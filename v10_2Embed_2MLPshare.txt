1. alternate update for rating, rank_u, rank_i
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [344.4 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [30.7], Init: 
Init_NDCG: [ 0.56655988  0.57013436  0.57655407  0.58627099  0.59744336  0.61154802
  0.62843613  0.64673022  0.66705792  0.68937433]
Iteration 0 [3.9 s]: rating_loss = 15.422400 [29.47 s],
NDCG: [ 0.56593008  0.56772002  0.57455616  0.58502495  0.59816603  0.61295267
  0.6295212   0.64809277  0.66797774  0.68984434]
Iteration 0 [79.1 s]: rank_loss = 0.632511 [28.66 s],
NDCG: [ 0.76020229  0.74490501  0.74100361  0.74091924  0.74536974  0.75288114
  0.76292169  0.77462582  0.78761265  0.80201747]
Iteration 0 [80.4 s]: rank_loss = 0.652605 [29.53 s],
NDCG: [ 0.74010335  0.73041338  0.72683222  0.7277475   0.7322272   0.74050813
  0.75120816  0.76334399  0.77759108  0.79221405]
Iteration 1 [0.5 s]: rating_loss = 9.425060 [28.72 s],
NDCG: [ 0.72629475  0.71956335  0.71772972  0.72011327  0.72488375  0.7336939
  0.74541444  0.75776501  0.77209831  0.78719733]
Iteration 1 [77.5 s]: rank_loss = 0.618545 [29.80 s],
NDCG: [ 0.75685411  0.74403458  0.73984132  0.74048181  0.74505893  0.75255305
  0.76271327  0.7744854   0.78752854  0.80189554]
Iteration 1 [88.9 s]: rank_loss = 0.644791 [27.45 s],
NDCG: [ 0.75461142  0.74200185  0.73795264  0.73897692  0.74362728  0.75142831
  0.76173454  0.77330929  0.78661903  0.80054446]
Iteration 2 [0.5 s]: rating_loss = 4.152434 [27.04 s],
NDCG: [ 0.75073483  0.73904579  0.73542453  0.73658131  0.74122015  0.74908492
  0.75899123  0.77123928  0.78456023  0.79877067]
Iteration 2 [77.5 s]: rank_loss = 0.615599 [28.75 s],
NDCG: [ 0.76028592  0.74677131  0.7424636   0.74186691  0.74626217  0.75384571
  0.76408022  0.77539073  0.78830629  0.80251477]
Iteration 2 [86.2 s]: rank_loss = 0.642573 [26.43 s],
NDCG: [ 0.75735073  0.7437749   0.73817985  0.73799103  0.74283779  0.75016404
  0.76048091  0.7721963   0.78585878  0.80009829]
Iteration 3 [0.5 s]: rating_loss = 2.285630 [27.25 s],
NDCG: [ 0.75618451  0.7429551   0.73759394  0.73766769  0.74238558  0.74963915
  0.75998857  0.771627    0.78536357  0.79964051]
Iteration 3 [74.9 s]: rank_loss = 0.615200 [27.17 s],
NDCG: [ 0.76108017  0.74584821  0.7420575   0.74196873  0.74651009  0.75385957
  0.7640283   0.77568394  0.78867526  0.8026276 ]
Iteration 3 [87.7 s]: rank_loss = 0.642527 [26.57 s],
NDCG: [ 0.75584542  0.74219437  0.73702139  0.7380443   0.74291423  0.75062101
  0.76110245  0.77260219  0.78550647  0.79986157]
Iteration 4 [0.5 s]: rating_loss = 1.515901 [25.61 s],
NDCG: [ 0.7559822   0.74220695  0.73692749  0.73804473  0.74304345  0.75069838
  0.76113299  0.77267715  0.78550749  0.79990141]
Iteration 4 [73.7 s]: rank_loss = 0.614445 [25.39 s],
NDCG: [ 0.76229185  0.74720817  0.74298559  0.74285138  0.74725165  0.7545832
  0.7644053   0.7758972   0.78920829  0.80327796]
Iteration 4 [88.0 s]: rank_loss = 0.642307 [27.45 s],
NDCG: [ 0.75528888  0.74276133  0.73804638  0.73821332  0.74326017  0.75121427
  0.76144927  0.77292454  0.78574471  0.80054804]
Iteration 5 [0.5 s]: rating_loss = 1.225531 [27.16 s],
NDCG: [ 0.75535491  0.74287339  0.73795804  0.73846495  0.74345066  0.75146912
  0.76162543  0.77296277  0.78588981  0.80059285]
Iteration 5 [75.9 s]: rank_loss = 0.614819 [28.37 s],
NDCG: [ 0.76305667  0.74789883  0.74375443  0.74331704  0.74706909  0.75461738
  0.76487448  0.77657378  0.7898064   0.80378787]
Iteration 5 [88.3 s]: rank_loss = 0.642535 [26.84 s],
NDCG: [ 0.75936168  0.74466408  0.73966961  0.74006759  0.74472128  0.75265549
  0.7625901   0.77440761  0.78778624  0.80177162]
Iteration 6 [0.4 s]: rating_loss = 1.119303 [27.95 s],
NDCG: [ 0.75960819  0.74496068  0.7398027   0.74021299  0.74500372  0.75285663
  0.76279701  0.7745901   0.7878955   0.80186652]
Iteration 6 [75.0 s]: rank_loss = 0.614246 [28.41 s],
NDCG: [ 0.76184078  0.74640119  0.74238699  0.74253429  0.74716939  0.75458139
  0.76462357  0.77592914  0.78931113  0.80334482]
Iteration 6 [89.5 s]: rank_loss = 0.641913 [28.34 s],
NDCG: [ 0.75770729  0.74525343  0.74017409  0.74086279  0.74542718  0.75273278
  0.76258851  0.77468855  0.78805401  0.8022845 ]
Iteration 7 [0.5 s]: rating_loss = 1.047050 [27.11 s],
NDCG: [ 0.75778747  0.74518855  0.74023944  0.74109164  0.74542594  0.75278214
  0.76265245  0.77474337  0.7881576   0.80227204]
Iteration 7 [75.1 s]: rank_loss = 0.614012 [27.78 s],
NDCG: [ 0.7648093   0.74770324  0.74281389  0.74389314  0.74817702  0.75536738
  0.76527142  0.77723417  0.79000437  0.80414523]
Iteration 7 [87.4 s]: rank_loss = 0.641951 [26.30 s],
NDCG: [ 0.75895306  0.74431354  0.74002708  0.74036845  0.74579493  0.75345379
  0.76317971  0.77485965  0.78819028  0.8023682 ]
Iteration 8 [0.4 s]: rating_loss = 1.016861 [25.93 s],
NDCG: [ 0.75889646  0.74434016  0.74005151  0.74049224  0.74588534  0.75354096
  0.76322532  0.77491115  0.78821038  0.80235274]
Iteration 8 [73.7 s]: rank_loss = 0.613968 [27.65 s],
NDCG: [ 0.76419055  0.74830338  0.74315571  0.74292318  0.74778055  0.75550362
  0.7655885   0.77706768  0.78990687  0.80376441]
Iteration 8 [88.1 s]: rank_loss = 0.641586 [24.77 s],
NDCG: [ 0.76009695  0.74492613  0.73958538  0.73986656  0.7443107   0.75214087
  0.76205507  0.77404428  0.78718129  0.80152524]
Iteration 9 [0.4 s]: rating_loss = 0.999707 [27.93 s],
NDCG: [ 0.75997778  0.74502746  0.73972549  0.7399479   0.7444694   0.75215164
  0.76203467  0.77397642  0.78712946  0.80154836]
Iteration 9 [74.6 s]: rank_loss = 0.613861 [28.24 s],
NDCG: [ 0.76331325  0.74822888  0.74353557  0.7434809   0.74785185  0.75515534
  0.76480973  0.77688308  0.78985733  0.80385382]
Iteration 9 [85.9 s]: rank_loss = 0.641723 [26.42 s],
NDCG: [ 0.76009475  0.74523621  0.74103482  0.7413869   0.74579909  0.75332949
  0.76342935  0.77522893  0.78845704  0.80267131]
Iteration 10 [0.4 s]: rating_loss = 0.965783 [25.27 s],
NDCG: [ 0.76000262  0.74524997  0.7409579   0.74134262  0.74571986  0.75338339
  0.76341647  0.77523264  0.78842789  0.80269839]
Iteration 10 [74.2 s]: rank_loss = 0.613701 [25.19 s],
NDCG: [ 0.76159867  0.74696336  0.74241313  0.74256637  0.7474388   0.75482915
  0.76558683  0.77717679  0.78969851  0.80364208]
Iteration 10 [87.5 s]: rank_loss = 0.641574 [28.01 s],
NDCG: [ 0.75984289  0.74588901  0.74071127  0.74113991  0.74587376  0.75410606
  0.7639087   0.77563853  0.78869367  0.80292017]
Iteration 11 [0.5 s]: rating_loss = 0.955966 [25.17 s],
NDCG: [ 0.75994791  0.74634882  0.74080696  0.7411902   0.74604165  0.75424236
  0.763918    0.77578592  0.78871337  0.80293583]
Iteration 11 [74.7 s]: rank_loss = 0.613601 [27.50 s],
NDCG: [ 0.76293876  0.7479575   0.74371458  0.74400684  0.74789572  0.75570068
  0.76582421  0.77724894  0.7901622   0.8040909 ]
Iteration 11 [89.3 s]: rank_loss = 0.641589 [28.27 s],
NDCG: [ 0.76043528  0.74507511  0.74049003  0.74135625  0.74576898  0.75381718
  0.7637238   0.7755609   0.78849372  0.80257872]
Iteration 12 [0.5 s]: rating_loss = 0.942808 [28.10 s],
NDCG: [ 0.7603834   0.74524007  0.74060124  0.74128854  0.74581302  0.75385563
  0.76376564  0.77559028  0.78847961  0.80263993]
Iteration 12 [75.8 s]: rank_loss = 0.613573 [28.24 s],
NDCG: [ 0.76033403  0.74552576  0.7422311   0.7424923   0.74684683  0.75493039
  0.76486387  0.77638561  0.78968195  0.80385969]
Iteration 12 [89.2 s]: rank_loss = 0.641121 [28.15 s],
NDCG: [ 0.75706931  0.7443933   0.74073533  0.74112878  0.74594524  0.75375255
  0.76394717  0.77538708  0.78875168  0.80292322]
Iteration 13 [0.4 s]: rating_loss = 0.912827 [25.55 s],
NDCG: [ 0.75694323  0.74461611  0.74072236  0.74121805  0.74603993  0.75382983
  0.76397593  0.77549336  0.78874849  0.80295654]
Iteration 13 [71.6 s]: rank_loss = 0.613387 [26.12 s],
NDCG: [ 0.76073367  0.74648021  0.7426556   0.74272801  0.74775622  0.75526918
  0.76513927  0.77670006  0.78978087  0.80391244]
Iteration 13 [85.7 s]: rank_loss = 0.640881 [27.14 s],
NDCG: [ 0.7601438   0.74533999  0.74168634  0.74210332  0.74680931  0.75445466
  0.76439444  0.7763242   0.78934093  0.80316715]
Iteration 14 [0.5 s]: rating_loss = 0.908439 [26.68 s],
NDCG: [ 0.75989383  0.74514935  0.74174178  0.74197139  0.74675389  0.75436715
  0.76429354  0.77633074  0.78922848  0.80313275]
Iteration 14 [74.9 s]: rank_loss = 0.613443 [27.79 s],
NDCG: [ 0.76164048  0.74783733  0.74291013  0.74339146  0.74805943  0.7552977
  0.76558708  0.77735463  0.79021782  0.80395659]
Iteration 14 [85.9 s]: rank_loss = 0.641358 [26.28 s],
NDCG: [ 0.75885747  0.74600896  0.74168148  0.74254809  0.74693417  0.75446063
  0.76471037  0.77641348  0.78923942  0.80313431]
Iteration 15 [0.4 s]: rating_loss = 0.894171 [27.58 s],
NDCG: [ 0.75929359  0.74643795  0.74185578  0.74279075  0.74708633  0.75454591
  0.76489136  0.77654387  0.78938077  0.80325599]
Iteration 15 [74.4 s]: rank_loss = 0.613384 [27.82 s],
NDCG: [ 0.7626127   0.74732942  0.74403229  0.74420617  0.7480088   0.75581722
  0.76555959  0.77738819  0.79017374  0.8039578 ]
Iteration 15 [87.1 s]: rank_loss = 0.641047 [27.47 s],
NDCG: [ 0.76325791  0.74672702  0.74281723  0.7429665   0.74738857  0.75489655
  0.76485025  0.77652666  0.78948918  0.80355082]
Iteration 16 [0.4 s]: rating_loss = 0.879612 [25.97 s],
NDCG: [ 0.76284538  0.74646673  0.74267987  0.74293546  0.74737044  0.75495082
  0.76488991  0.77644294  0.78944915  0.80345887]
Iteration 16 [75.1 s]: rank_loss = 0.613214 [27.12 s],
NDCG: [ 0.76251397  0.74814112  0.74359669  0.74407836  0.74799551  0.75570234
  0.76539896  0.77729789  0.7904484   0.80415092]
Iteration 16 [87.0 s]: rank_loss = 0.641111 [26.47 s],
NDCG: [ 0.75973913  0.7468177   0.74210475  0.74321509  0.74696373  0.75454417
  0.7640869   0.77608643  0.78904509  0.80318474]
Iteration 17 [0.5 s]: rating_loss = 0.874393 [26.50 s],
NDCG: [ 0.75983723  0.74700682  0.74237061  0.74319383  0.7469914   0.75468707
  0.76409495  0.77605946  0.78904106  0.8032078 ]
Iteration 17 [74.2 s]: rank_loss = 0.612889 [25.85 s],
NDCG: [ 0.76324928  0.7475741   0.74268928  0.74340512  0.7479993   0.75522982
  0.76521797  0.77692326  0.78986729  0.80385349]
Iteration 17 [88.0 s]: rank_loss = 0.640790 [28.18 s],
NDCG: [ 0.76209106  0.74632651  0.74153082  0.74153765  0.74646522  0.75375409
  0.76372646  0.77598608  0.78913018  0.80294483]
Iteration 18 [0.5 s]: rating_loss = 0.868386 [28.17 s],
NDCG: [ 0.76203509  0.74650892  0.74161263  0.74171979  0.74657158  0.7537801
  0.76381459  0.77598268  0.78915846  0.80305187]
Iteration 18 [76.2 s]: rank_loss = 0.613264 [28.14 s],
NDCG: [ 0.76275608  0.74631986  0.74266286  0.74301104  0.74722603  0.7553312
  0.76527726  0.7770019   0.78965612  0.80397415]
Iteration 18 [89.6 s]: rank_loss = 0.641111 [28.21 s],
NDCG: [ 0.760196    0.745107    0.74128926  0.74153004  0.74610029  0.75407892
  0.76382543  0.77568662  0.78866272  0.80280398]
Iteration 19 [0.5 s]: rating_loss = 0.876862 [28.13 s],
NDCG: [ 0.76009507  0.74498639  0.74115114  0.74164797  0.74602365  0.7540472
  0.76385651  0.77568645  0.78871434  0.80284464]
Iteration 19 [76.4 s]: rank_loss = 0.612778 [28.18 s],
NDCG: [ 0.7604881   0.74570571  0.74209863  0.74284607  0.7472654   0.75475288
  0.76507614  0.77674251  0.78935713  0.80350946]
Iteration 19 [89.7 s]: rank_loss = 0.640838 [28.16 s],
NDCG: [ 0.75980296  0.74518435  0.74103186  0.74153188  0.74602388  0.75366139
  0.76417885  0.77593569  0.78882362  0.8029615 ]
End. Best Iteration 16.

2. Alternate update for rank_u and rank_i with rating initialization
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [346.6 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [30.7], Init: 
Init_NDCG: [ 0.5600455   0.56366983  0.57205238  0.58267429  0.5958236   0.61053602
  0.62691519  0.64559816  0.66600881  0.68788993]
RatingInit_NDCG: [ 0.56241566  0.56581262  0.57392443  0.58497462  0.5974234   0.61224682
  0.62878644  0.64653954  0.66636272  0.68834213]
Iteration 0 [77.6 s]: rank_loss = 0.632860 [28.20 s],
NDCG: [ 0.75727464  0.74418635  0.73973663  0.74020163  0.74484898  0.75243137
  0.76264188  0.77432156  0.78721083  0.80125797]
Iteration 0 [80.5 s]: rank_loss = 0.657931 [26.37 s],
NDCG: [ 0.67996443  0.67231676  0.67153105  0.67548293  0.68284921  0.69318476
  0.70598374  0.72077567  0.7371872   0.75468104]
Iteration 1 [75.3 s]: rank_loss = 0.620111 [29.34 s],
NDCG: [ 0.75999777  0.7455856   0.74150827  0.74148518  0.74596267  0.7541733
  0.76440197  0.7759421   0.78893317  0.80288228]
Iteration 1 [85.2 s]: rank_loss = 0.645215 [27.64 s],
NDCG: [ 0.64732728  0.63902867  0.63777577  0.64110004  0.64914266  0.66017121
  0.67355571  0.68896622  0.70687015  0.72617162]
Iteration 2 [75.9 s]: rank_loss = 0.617278 [27.06 s],
NDCG: [ 0.76196372  0.74615052  0.74151386  0.74187821  0.74611387  0.75361329
  0.76363822  0.77547339  0.78857053  0.80254072]
Iteration 2 [88.0 s]: rank_loss = 0.643000 [28.60 s],
NDCG: [ 0.73795571  0.72342619  0.71683319  0.71676578  0.72120367  0.72916146
  0.73963819  0.7526196   0.767207    0.78282555]
Iteration 3 [75.2 s]: rank_loss = 0.615719 [28.69 s],
NDCG: [ 0.76070933  0.74605651  0.74145441  0.74238452  0.74634869  0.75429548
  0.76464452  0.77597644  0.78880232  0.80302207]
Iteration 3 [88.6 s]: rank_loss = 0.642820 [28.82 s],
NDCG: [ 0.75079632  0.73686254  0.73260353  0.73328598  0.73764974  0.74503049
  0.75521279  0.76738918  0.78099672  0.79554282]
Iteration 4 [76.1 s]: rank_loss = 0.614907 [28.57 s],
NDCG: [ 0.76286581  0.74776914  0.74332623  0.74343814  0.74762226  0.75490918
  0.76495744  0.77654334  0.78929371  0.80342742]
Iteration 4 [89.2 s]: rank_loss = 0.642441 [28.69 s],
NDCG: [ 0.76013846  0.74483076  0.73970805  0.73930525  0.74401668  0.7512355
  0.76096181  0.77258843  0.78609181  0.80026985]
Iteration 5 [76.1 s]: rank_loss = 0.615121 [29.24 s],
NDCG: [ 0.76155119  0.74572184  0.74137318  0.74214865  0.74681187  0.75434725
  0.76422819  0.77581871  0.78870832  0.80262485]
Iteration 5 [90.7 s]: rank_loss = 0.642235 [28.69 s],
NDCG: [ 0.7601438   0.7427353   0.73850434  0.7395541   0.74498837  0.75207994
  0.76173123  0.7731817   0.78629591  0.80050767]
Iteration 6 [76.2 s]: rank_loss = 0.614613 [28.78 s],
NDCG: [ 0.76419994  0.74581201  0.74181359  0.742468    0.74637748  0.75472634
  0.76432496  0.7760181   0.78890501  0.80301441]
Iteration 6 [89.8 s]: rank_loss = 0.642117 [28.76 s],
NDCG: [ 0.76275419  0.74371772  0.73945538  0.74027563  0.74464483  0.75256198
  0.76212099  0.7740746   0.78754195  0.8018099 ]
Iteration 7 [75.8 s]: rank_loss = 0.614333 [28.89 s],
NDCG: [ 0.76143453  0.74649827  0.7426672   0.74267082  0.74671518  0.75444364
  0.76433326  0.77600624  0.78913148  0.80329706]
Iteration 7 [89.7 s]: rank_loss = 0.641541 [28.82 s],
NDCG: [ 0.75949262  0.74554895  0.7417884   0.74095467  0.7455192   0.75343052
  0.7635289   0.77492881  0.788001    0.80237208]
Iteration 8 [76.4 s]: rank_loss = 0.614086 [28.62 s],
NDCG: [ 0.76452726  0.74790832  0.74291179  0.74324619  0.74790983  0.75544544
  0.76529156  0.77659179  0.78957693  0.80393092]
Iteration 8 [89.4 s]: rank_loss = 0.641859 [28.66 s],
NDCG: [ 0.76059469  0.74595049  0.7407096   0.74111471  0.74611695  0.75398056
  0.76376747  0.77534337  0.7886759   0.80269721]
Iteration 9 [76.6 s]: rank_loss = 0.613650 [30.71 s],
NDCG: [ 0.76385155  0.74715764  0.74232251  0.74261771  0.74661437  0.75443217
  0.76451387  0.77622346  0.78929921  0.80334376]
Iteration 9 [93.6 s]: rank_loss = 0.641797 [30.90 s],
NDCG: [ 0.76288122  0.74727304  0.74177536  0.74225808  0.74627029  0.75422039
  0.76420742  0.77571825  0.78879732  0.802877  ]
Iteration 10 [79.9 s]: rank_loss = 0.614057 [31.35 s],
NDCG: [ 0.76299567  0.74879738  0.74339049  0.74281247  0.74752911  0.75468826
  0.76454605  0.77619803  0.78955987  0.8038603 ]
Iteration 10 [93.9 s]: rank_loss = 0.641385 [31.05 s],
NDCG: [ 0.76177946  0.74660777  0.74179326  0.74135285  0.74632489  0.75341728
  0.76297951  0.7752817   0.78819492  0.80261519]
Iteration 11 [79.5 s]: rank_loss = 0.613747 [30.36 s],
NDCG: [ 0.76155842  0.74660871  0.74283197  0.74236234  0.74689022  0.75426185
  0.76446885  0.775997    0.78920891  0.80334127]
Iteration 11 [92.8 s]: rank_loss = 0.641495 [30.12 s],
NDCG: [ 0.76079215  0.74539948  0.74087545  0.74137009  0.74575029  0.75313326
  0.76302657  0.77478203  0.78787341  0.80200144]
Iteration 12 [78.6 s]: rank_loss = 0.613430 [29.53 s],
NDCG: [ 0.76186184  0.74717692  0.74279068  0.74301107  0.74739668  0.75484395
  0.76512844  0.77688481  0.78973874  0.80384822]
Iteration 12 [92.4 s]: rank_loss = 0.641360 [30.13 s],
NDCG: [ 0.75952155  0.74581145  0.74173386  0.74163495  0.74608155  0.75409266
  0.76394668  0.77531881  0.78851397  0.80271059]
Iteration 13 [78.7 s]: rank_loss = 0.613283 [30.53 s],
NDCG: [ 0.75974794  0.74625454  0.74200397  0.74249148  0.74681569  0.75483847
  0.76482885  0.77609251  0.78912617  0.80346038]
Iteration 13 [91.6 s]: rank_loss = 0.641232 [26.34 s],
NDCG: [ 0.75971838  0.74485056  0.74037853  0.74143229  0.74601943  0.75415669
  0.76386824  0.7753889   0.7885478   0.80276884]
Iteration 14 [75.8 s]: rank_loss = 0.612963 [28.62 s],
NDCG: [ 0.76049313  0.74704074  0.74240312  0.74262629  0.74698579  0.75486722
  0.76466704  0.77637264  0.78918194  0.80329176]
Iteration 14 [87.4 s]: rank_loss = 0.641038 [30.29 s],
NDCG: [ 0.75894349  0.74616106  0.74068169  0.74186344  0.74624715  0.75393459
  0.76386719  0.77511949  0.78788507  0.80206845]
Iteration 15 [77.7 s]: rank_loss = 0.612924 [29.93 s],
NDCG: [ 0.76229041  0.74804816  0.74305346  0.74298487  0.74729654  0.75509661
  0.76502776  0.77647892  0.78934567  0.8036224 ]
Iteration 15 [90.1 s]: rank_loss = 0.640756 [28.84 s],
NDCG: [ 0.75946401  0.74602759  0.74146143  0.74142568  0.74588584  0.75381749
  0.76382712  0.77519248  0.78847331  0.8027536 ]
Iteration 16 [76.9 s]: rank_loss = 0.613576 [30.21 s],
NDCG: [ 0.76175179  0.74672207  0.74176998  0.74231571  0.74662522  0.75449409
  0.76451451  0.77617437  0.78915033  0.80327265]
Iteration 16 [86.6 s]: rank_loss = 0.641148 [27.96 s],
NDCG: [ 0.76043654  0.74596812  0.74132732  0.74120327  0.74532858  0.75341119
  0.76363585  0.77520395  0.78851991  0.80252419]
Iteration 17 [76.7 s]: rank_loss = 0.612836 [30.31 s],
NDCG: [ 0.76205899  0.7464442   0.74167579  0.74163448  0.74661457  0.75421943
  0.7643611   0.77593397  0.78895988  0.80310119]
Iteration 17 [91.4 s]: rank_loss = 0.641145 [30.05 s],
NDCG: [ 0.76158923  0.7454612   0.74037281  0.74137816  0.7454065   0.75304964
  0.76328094  0.77497016  0.78784132  0.80205789]
Iteration 18 [77.9 s]: rank_loss = 0.612818 [29.01 s],
NDCG: [ 0.76347172  0.74714055  0.74187416  0.74168694  0.74650309  0.75490685
  0.76481352  0.77593101  0.78897067  0.80317301]
Iteration 18 [90.9 s]: rank_loss = 0.641218 [30.80 s],
NDCG: [ 0.76178795  0.74524419  0.74153895  0.74092088  0.74570169  0.7536442
  0.76398137  0.77542427  0.78818169  0.80234581]
Iteration 19 [77.5 s]: rank_loss = 0.613055 [25.84 s],
NDCG: [ 0.76194391  0.74694108  0.74284091  0.74254121  0.74690759  0.75463739
  0.76475596  0.77617781  0.78908736  0.80333012]
Iteration 19 [91.0 s]: rank_loss = 0.640913 [30.12 s],
NDCG: [ 0.7603856   0.74542795  0.7415675   0.74130027  0.74572949  0.75381276
  0.76419102  0.7752891   0.78815519  0.80234717]
End. Best Iteration 8.

liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [343.8 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [26.9], Init: 
Init_NDCG: [ 0.56012846  0.56682799  0.57637425  0.58630708  0.59913351  0.61370819
  0.63016994  0.64863016  0.6689168   0.6909162 ]
RatingInit_NDCG: [ 0.56685199  0.57301976  0.58048705  0.5904182   0.60180078  0.6161775
  0.63244417  0.65121633  0.67103214  0.69281741]
Iteration 0 [77.6 s]: rank_loss = 0.632103 [28.31 s],
NDCG: [ 0.75451961  0.74348315  0.73940586  0.73998675  0.74359976  0.75131361
  0.7619798   0.77355999  0.78659905  0.80107307]
Iteration 0 [81.4 s]: rank_loss = 0.651616 [28.53 s],
NDCG: [ 0.74157708  0.7300109   0.72701912  0.72875198  0.73393944  0.7421804
  0.75237775  0.76475393  0.77837512  0.79345189]
Iteration 1 [76.6 s]: rank_loss = 0.617331 [27.82 s],
NDCG: [ 0.76006299  0.74390109  0.73911542  0.74001059  0.74508228  0.75322477
  0.76304927  0.77469029  0.78772597  0.80191411]
Iteration 1 [88.1 s]: rank_loss = 0.644267 [28.45 s],
NDCG: [ 0.75588082  0.73981119  0.73548049  0.73617685  0.74184755  0.74995894
  0.76005854  0.77198308  0.78511392  0.79961419]
Iteration 2 [76.9 s]: rank_loss = 0.615582 [28.07 s],
NDCG: [ 0.76152006  0.74623924  0.74114229  0.74106624  0.7458661   0.75334603
  0.7639504   0.77573242  0.78881744  0.80282859]
Iteration 2 [89.0 s]: rank_loss = 0.643153 [28.08 s],
NDCG: [ 0.75743805  0.74436771  0.7383151   0.73836961  0.7436451   0.75173146
  0.76164163  0.77359352  0.78668232  0.80102529]
Iteration 3 [76.7 s]: rank_loss = 0.614525 [27.87 s],
NDCG: [ 0.75977466  0.74645818  0.74184258  0.7415802   0.74648792  0.75402678
  0.76395811  0.77580552  0.78874197  0.80285496]
Iteration 3 [89.1 s]: rank_loss = 0.642962 [27.84 s],
NDCG: [ 0.75500383  0.74104862  0.73646499  0.73795345  0.74300389  0.75106958
  0.76097969  0.77294644  0.78603968  0.80062716]
Iteration 4 [76.4 s]: rank_loss = 0.614734 [26.71 s],
NDCG: [ 0.75925823  0.74713727  0.74148307  0.74227216  0.74640514  0.75404302
  0.76436469  0.77608299  0.78893539  0.80286778]
Iteration 4 [90.2 s]: rank_loss = 0.642432 [28.12 s],
NDCG: [ 0.7575251   0.74424512  0.73898764  0.73990066  0.7448582   0.75245869
  0.76211443  0.7742611   0.78722779  0.8012998 ]
Iteration 5 [77.1 s]: rank_loss = 0.614507 [28.32 s],
NDCG: [ 0.75994634  0.74702004  0.74221361  0.74161253  0.74617525  0.75406064
  0.76421935  0.77606586  0.78890293  0.80319006]
Iteration 5 [92.9 s]: rank_loss = 0.642068 [29.84 s],
NDCG: [ 0.75604603  0.7440796   0.73926317  0.73949946  0.74389635  0.75166256
  0.76194467  0.77367776  0.78703051  0.80157748]
Iteration 6 [79.4 s]: rank_loss = 0.614116 [28.48 s],
NDCG: [ 0.76026957  0.7455871   0.74157299  0.74096199  0.74615426  0.75447989
  0.76435734  0.77616342  0.78875395  0.80311763]
Iteration 6 [93.3 s]: rank_loss = 0.642216 [29.50 s],
NDCG: [ 0.75738532  0.74343563  0.73846805  0.73904142  0.74397999  0.75194769
  0.76252705  0.77421867  0.78724609  0.80119349]
Iteration 7 [78.9 s]: rank_loss = 0.613928 [29.68 s],
NDCG: [ 0.76185304  0.74729386  0.74194938  0.74262754  0.7468725   0.75430724
  0.76450066  0.77640462  0.78934769  0.80343466]
Iteration 7 [92.9 s]: rank_loss = 0.642184 [29.43 s],
NDCG: [ 0.75966524  0.74529472  0.74101448  0.74061626  0.74528167  0.75279529
  0.76329328  0.77521852  0.78810707  0.80215976]
Iteration 8 [78.6 s]: rank_loss = 0.613733 [29.13 s],
NDCG: [ 0.76342927  0.74836771  0.74286178  0.74326848  0.74719298  0.75506367
  0.76536331  0.77713375  0.78970138  0.80371293]
Iteration 8 [92.7 s]: rank_loss = 0.641887 [29.13 s],
NDCG: [ 0.76145987  0.74563448  0.7410118   0.74110732  0.74567404  0.75348121
  0.76343926  0.77572157  0.78816107  0.80250308]
Iteration 9 [78.7 s]: rank_loss = 0.613389 [29.02 s],
NDCG: [ 0.76327897  0.74686606  0.74244382  0.74296814  0.74736757  0.75485105
  0.76457676  0.77633848  0.78919739  0.80368769]
Iteration 9 [92.6 s]: rank_loss = 0.641850 [29.01 s],
NDCG: [ 0.76365189  0.7462197   0.7417629   0.7418346   0.74683729  0.75434678
  0.76429701  0.7760501   0.78881074  0.80308001]
Iteration 10 [79.2 s]: rank_loss = 0.613868 [29.03 s],
NDCG: [ 0.76156942  0.74626041  0.74270395  0.74227473  0.74701603  0.75489621
  0.76474413  0.77642816  0.7894491   0.80355799]
Iteration 10 [92.6 s]: rank_loss = 0.641604 [28.79 s],
NDCG: [ 0.76220803  0.74637928  0.74088034  0.74077681  0.74577032  0.75362142
  0.76342512  0.7752231   0.78835055  0.80262327]
Iteration 11 [78.4 s]: rank_loss = 0.613651 [28.77 s],
NDCG: [ 0.76156942  0.74621377  0.74135059  0.74185219  0.7466408   0.75430587
  0.76444955  0.77632555  0.78937099  0.80334626]
Iteration 11 [92.9 s]: rank_loss = 0.641562 [29.21 s],
NDCG: [ 0.75938729  0.74501865  0.74060123  0.74085633  0.74622317  0.75354163
  0.76378584  0.77543546  0.78850817  0.80265632]
Iteration 12 [79.0 s]: rank_loss = 0.613094 [29.19 s],
NDCG: [ 0.76238379  0.74765663  0.74231488  0.74254474  0.74673316  0.7544547
  0.76454728  0.77610998  0.78956625  0.80381681]
Iteration 12 [93.3 s]: rank_loss = 0.641098 [29.31 s],
NDCG: [ 0.7603056   0.74484985  0.74047916  0.74091182  0.74530012  0.75268768
  0.76282346  0.77508226  0.78805574  0.8024766 ]
Iteration 13 [79.5 s]: rank_loss = 0.613232 [29.17 s],
NDCG: [ 0.76185555  0.74735222  0.742633    0.74232365  0.74664542  0.75446133
  0.76473152  0.7764269   0.78933047  0.80353532]
Iteration 13 [92.0 s]: rank_loss = 0.641832 [28.19 s],
NDCG: [ 0.7609783   0.74616436  0.7415597   0.74141825  0.74604712  0.753618
  0.76382945  0.77553502  0.78869278  0.80274896]
Iteration 14 [76.9 s]: rank_loss = 0.613451 [28.05 s],
NDCG: [ 0.76110802  0.74638039  0.74160565  0.74194818  0.7464297   0.75418157
  0.76383427  0.77591488  0.78915591  0.80340308]
Iteration 14 [90.8 s]: rank_loss = 0.641560 [28.07 s],
NDCG: [ 0.76154225  0.74596419  0.74108521  0.74089511  0.74563479  0.75340873
  0.76329926  0.77502515  0.78846367  0.80292687]
Iteration 15 [77.1 s]: rank_loss = 0.613247 [28.50 s],
NDCG: [ 0.76017273  0.74622975  0.74201458  0.74175685  0.74620974  0.75411577
  0.76434619  0.77587498  0.78918938  0.80337485]
Iteration 15 [91.3 s]: rank_loss = 0.642019 [27.33 s],
NDCG: [ 0.76004934  0.74598729  0.74066597  0.74105072  0.74561871  0.75364614
  0.76373566  0.77555782  0.7885799   0.80280235]
Iteration 16 [77.0 s]: rank_loss = 0.612934 [27.95 s],
NDCG: [ 0.76083617  0.74703222  0.74297749  0.74274412  0.74678065  0.7544507
  0.76471393  0.77649376  0.7896656   0.80364028]
Iteration 16 [90.3 s]: rank_loss = 0.641264 [28.04 s],
NDCG: [ 0.76195334  0.74639145  0.74259302  0.74287854  0.7466205   0.75386101
  0.76404962  0.77607591  0.7893026   0.80322508]
Iteration 17 [77.0 s]: rank_loss = 0.612704 [27.28 s],
NDCG: [ 0.76182914  0.74702778  0.74242632  0.74265103  0.74732919  0.75513415
  0.7652144   0.77685576  0.78977175  0.80362814]
Iteration 17 [90.7 s]: rank_loss = 0.641153 [28.10 s],
NDCG: [ 0.76079624  0.74682827  0.7416642   0.74152468  0.74660408  0.75430579
  0.7645033   0.77576919  0.78882577  0.80277662]
Iteration 18 [76.9 s]: rank_loss = 0.613481 [27.88 s],
NDCG: [ 0.76105313  0.74723893  0.74295866  0.74244733  0.74730526  0.75474049
  0.76524802  0.77655921  0.78938195  0.80368024]
Iteration 18 [90.4 s]: rank_loss = 0.641012 [28.07 s],
NDCG: [ 0.76277494  0.74714241  0.74234497  0.74280127  0.74680236  0.75489769
  0.76513348  0.77652503  0.78939418  0.80351987]
Iteration 19 [77.1 s]: rank_loss = 0.613189 [28.00 s],
NDCG: [ 0.76066984  0.74649983  0.74242457  0.74225938  0.74679583  0.75469402
  0.76463635  0.77625985  0.78898133  0.80344532]
Iteration 19 [90.4 s]: rank_loss = 0.640552 [28.14 s],
NDCG: [ 0.75899582  0.74510797  0.74131876  0.74098932  0.7456866   0.75358551
  0.76342836  0.77504987  0.78800323  0.80248067]
End. Best Iteration 12.



3. Update for rank_u with rating initialization
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [351.2 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [33.3], Init: 
Init_NDCG: [ 0.56138905  0.56660478  0.57314163  0.58355276  0.59590144  0.61033113
  0.62721119  0.64590306  0.66583025  0.68759003]
RatingInit_NDCG: [ 0.55067452  0.55950643  0.56926048  0.57937974  0.5925191   0.60757687
  0.6247652   0.64356505  0.66365497  0.68604586]
Iteration 0 [81.9 s]: rank_loss = 0.632317 [32.38 s],
NDCG: [ 0.73609815  0.7263067   0.7255052   0.72794024  0.73424191  0.74334088
  0.75424781  0.76679503  0.78045468  0.79496166]
Iteration 1 [79.2 s]: rank_loss = 0.616398 [32.91 s],
NDCG: [ 0.74032188  0.7310089   0.72912054  0.73191847  0.73754825  0.74557225
  0.75591005  0.76833077  0.78211952  0.79663494]
Iteration 2 [79.9 s]: rank_loss = 0.615341 [30.92 s],
NDCG: [ 0.74174642  0.73116884  0.72911214  0.73182073  0.73832092  0.74668895
  0.7567254   0.76863387  0.78231081  0.79664626]
Iteration 3 [78.7 s]: rank_loss = 0.614782 [30.40 s],
NDCG: [ 0.7421316   0.732379    0.73097139  0.73311344  0.73867149  0.74761595
  0.757723    0.76986446  0.78314335  0.79778997]
Iteration 4 [77.8 s]: rank_loss = 0.614118 [29.67 s],
NDCG: [ 0.74255181  0.73068054  0.72858264  0.73212937  0.73786462  0.74645223
  0.75716119  0.76911415  0.78252729  0.79692436]
Iteration 5 [80.2 s]: rank_loss = 0.613934 [26.61 s],
NDCG: [ 0.74069214  0.73070532  0.72841181  0.73090736  0.73664004  0.74564665
  0.75671254  0.76895283  0.78252058  0.79676074]
Iteration 6 [109.5 s]: rank_loss = 0.613895 [27.15 s],
NDCG: [ 0.73910365  0.73004003  0.72678656  0.72968451  0.7365458   0.74528945
  0.75558716  0.76807069  0.78188768  0.796635  ]
Iteration 7 [93.6 s]: rank_loss = 0.613719 [28.59 s],
NDCG: [ 0.74047249  0.73033756  0.72724932  0.73015672  0.73605334  0.7452576
  0.7559172   0.76785549  0.78146269  0.79641538]
Iteration 8 [118.4 s]: rank_loss = 0.613670 [28.20 s],
NDCG: [ 0.73857855  0.72970318  0.72695181  0.72877619  0.73550216  0.74427393
  0.75504765  0.76754573  0.78147031  0.79602756]
Iteration 9 [95.1 s]: rank_loss = 0.613431 [29.06 s],
NDCG: [ 0.73802704  0.72988224  0.72691315  0.72980104  0.73605882  0.74493447
  0.75545256  0.76804123  0.7820996   0.79643014]
Iteration 10 [103.8 s]: rank_loss = 0.613543 [29.95 s],
NDCG: [ 0.73615933  0.72672303  0.72496081  0.72750438  0.73424779  0.7430865
  0.75444267  0.7668699   0.78086899  0.79533406]
Iteration 11 [125.9 s]: rank_loss = 0.613247 [28.71 s],
NDCG: [ 0.73612079  0.72622862  0.72341772  0.72597033  0.73322471  0.74175467
  0.75345726  0.76615228  0.77991003  0.79452323]
Iteration 12 [144.9 s]: rank_loss = 0.613334 [28.63 s],
NDCG: [ 0.73089058  0.72443433  0.72176729  0.72458678  0.73096895  0.74039354
  0.75156743  0.76464174  0.77845738  0.79340152]
Iteration 13 [143.1 s]: rank_loss = 0.612944 [28.44 s],
NDCG: [ 0.72999666  0.72180572  0.72127283  0.72433554  0.73074238  0.74022967
  0.75145615  0.76407358  0.77821703  0.79294773]
Iteration 14 [140.1 s]: rank_loss = 0.612763 [26.78 s],
NDCG: [ 0.72459917  0.71999451  0.71941448  0.72198827  0.72898195  0.73805254
  0.74961902  0.76279994  0.77669066  0.79165278]
Iteration 15 [137.1 s]: rank_loss = 0.612986 [25.65 s],
NDCG: [ 0.72462136  0.71766846  0.71651231  0.72005603  0.72754194  0.73706643
  0.74784177  0.7611171   0.77553077  0.7905588 ]
Iteration 16 [109.6 s]: rank_loss = 0.612640 [25.35 s],
NDCG: [ 0.72196663  0.71560842  0.7151169   0.71863883  0.7261549   0.73576669
  0.74693491  0.75982517  0.77425393  0.78947327]
Iteration 17 [78.7 s]: rank_loss = 0.612725 [27.42 s],
NDCG: [ 0.72304463  0.71315388  0.71326611  0.71749803  0.72474146  0.73460242
  0.74600459  0.75921918  0.77355443  0.78896821]
Iteration 18 [79.3 s]: rank_loss = 0.612647 [26.17 s],
NDCG: [ 0.71806282  0.71027415  0.70966246  0.7140949   0.72216497  0.73194182
  0.74352785  0.75713045  0.7714595   0.78692889]
Iteration 19 [83.6 s]: rank_loss = 0.612559 [27.22 s],
NDCG: [ 0.71514038  0.70693277  0.7078819   0.71137411  0.71975788  0.73005012
  0.74199569  0.75579458  0.77040798  0.78584912]
End. Best Iteration 3.

4. Alternate update for rank_u and rank_i with rating initialization, Delete labels equaling to 0.5
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
v10_2Embed_2MLPshare/MLP.py:170: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer
  np.delete(train_user, train_user[:, 3] == 0.5, axis = 0)
v10_2Embed_2MLPshare/MLP.py:171: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer
  np.delete(train_item, train_item[:, 3] == 0.5, axis = 0)
Load data done [369.9 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [32.9], Init: 
Init_NDCG: [ 0.55382645  0.56047564  0.56854947  0.57909706  0.59176499  0.60684071
  0.62359544  0.64267233  0.66336415  0.68555833]
RatingInit_NDCG: [ 0.56395771  0.56609623  0.57388792  0.58397524  0.59686008  0.61140106
  0.62782714  0.64606973  0.66641648  0.68830806]
Iteration 0 [80.2 s]: rank_loss = 0.630014 [32.09 s],
NDCG: [ 0.76025071  0.74544271  0.74119516  0.74081192  0.74553572  0.75318314
  0.76318106  0.77448654  0.78765282  0.80193515]
Iteration 0 [84.9 s]: rank_loss = 0.654503 [30.20 s],
NDCG: [ 0.45374543  0.46919141  0.48419009  0.5001065   0.51770405  0.53652774
  0.55629581  0.57878142  0.60279708  0.62903695]
Iteration 1 [78.6 s]: rank_loss = 0.617947 [27.58 s],
NDCG: [ 0.75761359  0.74331107  0.73904753  0.73977389  0.74407395  0.75163446
  0.76151185  0.77325228  0.78617778  0.80023692]
Iteration 1 [87.0 s]: rank_loss = 0.644385 [27.77 s],
NDCG: [ 0.73377515  0.72340984  0.71937282  0.72071829  0.72677624  0.73542866
  0.74625615  0.7591236   0.77317366  0.78825551]
Iteration 2 [77.5 s]: rank_loss = 0.615495 [30.16 s],
NDCG: [ 0.75444226  0.74027384  0.73497087  0.73549789  0.74003186  0.74797716
  0.75793092  0.77007208  0.78356253  0.79792951]
Iteration 2 [91.1 s]: rank_loss = 0.642913 [28.15 s],
NDCG: [ 0.74480438  0.73087233  0.72665609  0.72717976  0.73182689  0.73966641
  0.74986161  0.76227149  0.77583102  0.79085779]
Iteration 3 [75.8 s]: rank_loss = 0.615386 [29.15 s],
NDCG: [ 0.75259813  0.73945637  0.73448352  0.73497977  0.73890256  0.7468877
  0.7570962   0.76907047  0.78258957  0.79734438]
Iteration 3 [89.3 s]: rank_loss = 0.642392 [30.17 s],
NDCG: [ 0.74260463  0.72955822  0.72460598  0.72539062  0.72916304  0.73703156
  0.74726484  0.75978167  0.77406239  0.78939531]
Iteration 4 [79.7 s]: rank_loss = 0.615016 [30.29 s],
NDCG: [ 0.74005178  0.72699499  0.72113249  0.72049687  0.72467739  0.73182014
  0.74170618  0.75435068  0.76921352  0.78474581]
Iteration 4 [92.3 s]: rank_loss = 0.642338 [29.36 s],
NDCG: [ 0.74748677  0.73375103  0.7286468   0.72917634  0.73352559  0.74165078
  0.75182639  0.76407359  0.77813596  0.79322361]
Iteration 5 [78.7 s]: rank_loss = 0.614267 [29.27 s],
NDCG: [ 0.75177653  0.73757432  0.73303507  0.73294495  0.73784812  0.74517358
  0.75518387  0.76715926  0.780717    0.7954888 ]
Iteration 5 [91.4 s]: rank_loss = 0.641799 [29.23 s],
NDCG: [ 0.75009213  0.73690601  0.73249533  0.73243172  0.73617918  0.7442331
  0.75396884  0.76624137  0.77998445  0.79495332]
Iteration 6 [78.0 s]: rank_loss = 0.613901 [28.96 s],
NDCG: [ 0.75028425  0.73791165  0.73247472  0.73246518  0.73688655  0.74466793
  0.75500478  0.76715635  0.78094548  0.79584677]
Iteration 6 [90.8 s]: rank_loss = 0.641887 [29.03 s],
NDCG: [ 0.7278293   0.71593933  0.71147578  0.71335625  0.71873856  0.72756923
  0.73809422  0.75154177  0.76657279  0.78202924]
Iteration 7 [78.2 s]: rank_loss = 0.614306 [29.80 s],
NDCG: [ 0.7247721   0.71388305  0.70912525  0.70979394  0.71457827  0.72229537
  0.73263317  0.74572975  0.76040445  0.77621296]
Iteration 7 [91.8 s]: rank_loss = 0.641552 [29.37 s],
NDCG: [ 0.70289934  0.69468053  0.69099606  0.69361102  0.69876758  0.7074727
  0.71847995  0.73262597  0.74843082  0.76517828]
Iteration 8 [79.0 s]: rank_loss = 0.613941 [28.93 s],
NDCG: [ 0.70230853  0.69302772  0.6897547   0.69108449  0.69629407  0.70470283
  0.71601742  0.7299492   0.74562456  0.76263422]
Iteration 8 [92.0 s]: rank_loss = 0.641848 [29.78 s],
NDCG: [ 0.65411818  0.64960984  0.64977608  0.65371926  0.66171025  0.67263546
  0.68563744  0.70125534  0.71870068  0.73735477]
Iteration 9 [79.0 s]: rank_loss = 0.613922 [29.14 s],
NDCG: [ 0.63822631  0.63492027  0.63822653  0.64462112  0.65418552  0.66610554
  0.68003868  0.69653074  0.7143375   0.73329499]

5. Update for rank_u with rating initialization, using nonall dataset
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Time: [31.4], Init: 
Init_NDCG: [ 0.56719521  0.57194209  0.57827502  0.58782244  0.59999062  0.61414007
  0.63071532  0.64874928  0.66905192  0.69090218]
RatingInit_NDCG: [ 0.564155    0.5685003   0.57522368  0.58530107  0.59727637  0.61176048
  0.62827876  0.64646366  0.66639928  0.68846225]
Iteration 0 [81.1 s]: rank_loss = 0.347365 [30.98 s],
NDCG: [ 0.75117521  0.73900762  0.73313761  0.73377461  0.73848096  0.74625606
  0.75600076  0.76771147  0.78093442  0.79522508]
Iteration 1 [81.9 s]: rank_loss = 0.308831 [30.43 s],
NDCG: [ 0.75448866  0.73997792  0.735314    0.73500505  0.73941311  0.74717964
  0.75711334  0.76858667  0.78173247  0.79628181]
Iteration 2 [80.6 s]: rank_loss = 0.307217 [30.06 s],
NDCG: [ 0.75238419  0.7402861   0.73465347  0.73568882  0.73964041  0.74659892
  0.75659046  0.76846841  0.78199161  0.79663405]
Iteration 3 [81.1 s]: rank_loss = 0.307335 [30.40 s],
NDCG: [ 0.75266407  0.73979167  0.73482435  0.73532247  0.7394592   0.74717936
  0.75695057  0.76889543  0.78205684  0.79673419]
Iteration 4 [80.6 s]: rank_loss = 0.306517 [30.10 s],
NDCG: [ 0.75277224  0.73969416  0.73507568  0.73558519  0.73976821  0.74685254
  0.75714447  0.76905414  0.78203422  0.7967305 ]
Iteration 5 [79.6 s]: rank_loss = 0.305289 [30.36 s],
NDCG: [ 0.7541082   0.73971955  0.73569412  0.73615159  0.74041014  0.74780181
  0.75801961  0.76951963  0.78243222  0.79720221]
Iteration 6 [79.4 s]: rank_loss = 0.305826 [30.16 s],
NDCG: [ 0.75272314  0.73961752  0.73496453  0.73585368  0.73974459  0.74753886
  0.75754494  0.76912756  0.78222934  0.79681218]
Iteration 7 [79.0 s]: rank_loss = 0.305842 [30.65 s],
NDCG: [ 0.75242291  0.73830025  0.73382441  0.73576199  0.73993325  0.74750427
  0.75715573  0.76868596  0.78183258  0.79652812]
Iteration 8 [80.9 s]: rank_loss = 0.305289 [31.87 s],
NDCG: [ 0.75063097  0.73822882  0.73380551  0.73507193  0.73940253  0.74712423
  0.75705682  0.76890812  0.78162507  0.79623542]
Iteration 9 [81.0 s]: rank_loss = 0.305552 [30.45 s],
NDCG: [ 0.7525427   0.7386709   0.73496905  0.73574871  0.73987479  0.74742502
  0.75744727  0.76875003  0.78195259  0.79664187]
Iteration 10 [79.7 s]: rank_loss = 0.305658 [31.76 s],
NDCG: [ 0.75122363  0.73827512  0.73450213  0.73521417  0.739297    0.74716503
  0.75733652  0.7688632   0.7815293   0.79628152]
Iteration 11 [80.7 s]: rank_loss = 0.305742 [31.12 s],
NDCG: [ 0.75206881  0.7392382   0.73500518  0.7346787   0.73938726  0.74732427
  0.7572513   0.76876183  0.78167438  0.79641282]
Iteration 12 [79.3 s]: rank_loss = 0.305169 [29.19 s],
NDCG: [ 0.75124564  0.74005934  0.73469559  0.735167    0.73959985  0.74765736
  0.7571586   0.76897559  0.78219393  0.79675572]
Iteration 13 [79.9 s]: rank_loss = 0.305367 [30.21 s],
NDCG: [ 0.75239613  0.73942757  0.73452074  0.73525346  0.73934947  0.74719873
  0.75722656  0.76883189  0.78213203  0.79665058]
Iteration 14 [79.5 s]: rank_loss = 0.304703 [29.06 s],
NDCG: [ 0.75218955  0.74004866  0.73497673  0.73532013  0.73948373  0.74756116
  0.75765309  0.76924654  0.78203418  0.79672896]
Iteration 15 [79.3 s]: rank_loss = 0.304900 [29.13 s],
NDCG: [ 0.75232696  0.73878837  0.73533525  0.7355421   0.73969083  0.7474991
  0.7575647   0.76923411  0.78196727  0.79652202]
Iteration 16 [78.8 s]: rank_loss = 0.304708 [29.12 s],
NDCG: [ 0.74947635  0.73809983  0.73442399  0.73509468  0.73956871  0.74747769
  0.7572916   0.7690122   0.78190534  0.79654756]
Iteration 17 [79.6 s]: rank_loss = 0.305231 [29.16 s],
NDCG: [ 0.75231784  0.73875545  0.73514949  0.73532777  0.73994569  0.74771566
  0.75779073  0.76934398  0.78228894  0.79697147]
Iteration 18 [79.2 s]: rank_loss = 0.305131 [29.22 s],
NDCG: [ 0.75182765  0.73944285  0.73532046  0.73531188  0.73999676  0.7475403
  0.75770345  0.76938111  0.78238135  0.7968505 ]
Iteration 19 [79.3 s]: rank_loss = 0.304861 [29.19 s],
NDCG: [ 0.75289513  0.739664    0.73564362  0.73629481  0.74029867  0.7480472
  0.7580149   0.76944645  0.78239516  0.79708117]
End. Best Iteration 5.

6. Alternate update for rank_u and rank_i with rating initialization, using nonall dataset
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [80.4 s]. #user=13679, #item=12922, #train_user=3914489, #train_item=5115233, #test=316795
Time: [32.0], Init: 
Init_NDCG: [ 0.5640135   0.56859154  0.57522265  0.58603656  0.59866405  0.61304983
  0.62938485  0.64802694  0.66818047  0.68983203]
RatingInit_NDCG: [ 0.56135662  0.56661187  0.57511515  0.58531798  0.59749748  0.61171781
  0.62828247  0.64698085  0.66730054  0.689694  ]
Iteration 0 [83.2 s]: rank_loss = 0.342916 [31.63 s],
NDCG: [ 0.75256611  0.73917248  0.73560163  0.73563532  0.73965533  0.74756776
  0.75754477  0.76895992  0.78241956  0.7968704 ]
Iteration 0 [86.7 s]: rank_loss = 0.398896 [30.64 s],
NDCG: [ 0.7626215   0.74804415  0.74280365  0.74280325  0.74732544  0.75427909
  0.76395919  0.77576118  0.788513    0.80272023]
Iteration 1 [82.4 s]: rank_loss = 0.311908 [30.79 s],
NDCG: [ 0.75925199  0.74546127  0.73974226  0.74042428  0.74379983  0.751979
  0.76229083  0.7734787   0.78607975  0.80040608]
Iteration 1 [93.4 s]: rank_loss = 0.387207 [31.03 s],
NDCG: [ 0.76658663  0.75101003  0.74556117  0.74574872  0.74967707  0.75675209
  0.76685971  0.77829766  0.79080228  0.80483855]
Iteration 2 [82.9 s]: rank_loss = 0.310026 [32.39 s],
NDCG: [ 0.75817754  0.74540841  0.74014597  0.74102656  0.74483565  0.75292472
  0.76288947  0.77439511  0.78738468  0.80165357]
Iteration 2 [95.9 s]: rank_loss = 0.385327 [29.86 s],
NDCG: [ 0.76428092  0.75032159  0.74601301  0.74582751  0.74938445  0.75648467
  0.76663699  0.77822756  0.79105585  0.80508585]
Iteration 3 [106.9 s]: rank_loss = 0.308209 [38.54 s],
NDCG: [ 0.76007045  0.74829072  0.74257608  0.74273227  0.74656124  0.75449281
  0.76461821  0.77631914  0.78911831  0.80326414]
Iteration 3 [134.6 s]: rank_loss = 0.383802 [22.02 s],
NDCG: [ 0.76224342  0.75016616  0.74476405  0.74504831  0.74833534  0.75590898
  0.76554768  0.77679911  0.79001079  0.80418431]
Iteration 4 [75.4 s]: rank_loss = 0.307474 [21.62 s],
NDCG: [ 0.75989163  0.74578975  0.74201019  0.74213984  0.74605342  0.75370562
  0.76400545  0.77592371  0.78874457  0.8028503 ]
Iteration 4 [83.0 s]: rank_loss = 0.382785 [21.03 s],
NDCG: [ 0.76043591  0.74854935  0.7432107   0.74301802  0.74699837  0.75459339
  0.76510646  0.7768695   0.78953047  0.8036499 ]
Iteration 5 [69.2 s]: rank_loss = 0.307096 [20.67 s],
NDCG: [ 0.75730828  0.74612655  0.74074742  0.74145396  0.7462695   0.75408059
  0.76359919  0.77531032  0.78819095  0.80266707]
Iteration 5 [82.2 s]: rank_loss = 0.382708 [22.32 s],
NDCG: [ 0.7590004   0.74690946  0.74281296  0.74291656  0.74729473  0.75506693
  0.76481375  0.77663383  0.78911159  0.80331804]
Iteration 6 [72.5 s]: rank_loss = 0.306491 [20.77 s],
NDCG: [ 0.76080428  0.7471674   0.74315101  0.74311324  0.74737795  0.75502183
  0.7647096   0.77636278  0.78911877  0.80335998]
Iteration 6 [81.3 s]: rank_loss = 0.382073 [20.54 s],
NDCG: [ 0.76202503  0.74860668  0.74449044  0.74463485  0.74844559  0.75604309
  0.76572008  0.7773323   0.78986226  0.80391823]
Iteration 7 [69.4 s]: rank_loss = 0.306124 [20.66 s],
NDCG: [ 0.7588842   0.74658394  0.74220758  0.7432057   0.74694618  0.75455701
  0.76431471  0.77563951  0.78836456  0.80269581]
Iteration 7 [80.5 s]: rank_loss = 0.382083 [20.50 s],
NDCG: [ 0.7618304   0.74761209  0.74353165  0.74397127  0.74833631  0.75553288
  0.76498556  0.77664526  0.78931675  0.80308536]
Iteration 8 [69.5 s]: rank_loss = 0.305343 [20.50 s],
NDCG: [ 0.75725393  0.74629657  0.74242095  0.74211758  0.74617218  0.75384426
  0.76342876  0.77491829  0.78771056  0.8019048 ]
Iteration 8 [81.3 s]: rank_loss = 0.381777 [20.53 s],
NDCG: [ 0.75883173  0.74616437  0.74211643  0.74318909  0.74694815  0.75454282
  0.76412367  0.77527498  0.78827167  0.80251571]
Iteration 9 [70.2 s]: rank_loss = 0.305586 [20.40 s],
NDCG: [ 0.75506204  0.74353296  0.73991407  0.7403573   0.74459029  0.75196829
  0.7615306   0.77310821  0.78588349  0.80029441]
Iteration 9 [80.6 s]: rank_loss = 0.381879 [20.60 s],
NDCG: [ 0.75805855  0.74594946  0.74251608  0.74258557  0.7460369   0.75393153
  0.76377314  0.77526746  0.78767101  0.80196647]
Iteration 10 [69.3 s]: rank_loss = 0.305438 [20.41 s],
NDCG: [ 0.7561638   0.74588176  0.74050421  0.74050359  0.74452112  0.75185042
  0.76146701  0.77284698  0.78574198  0.80029817]
Iteration 10 [82.1 s]: rank_loss = 0.381604 [20.49 s],
NDCG: [ 0.75495797  0.74555655  0.74058505  0.74106209  0.7453789   0.75284336
  0.76266419  0.77401724  0.78664556  0.80102581]
Iteration 11 [70.5 s]: rank_loss = 0.305677 [21.51 s],
NDCG: [ 0.75306385  0.7413961   0.73709486  0.73729625  0.74158416  0.74906297
  0.75917392  0.77054056  0.78331006  0.79817418]
Iteration 11 [80.9 s]: rank_loss = 0.381878 [20.50 s],
NDCG: [ 0.7545033   0.74172535  0.73748897  0.73797291  0.74188136  0.74958873
  0.75949246  0.77127988  0.78395407  0.79875925]
Iteration 12 [69.5 s]: rank_loss = 0.304920 [20.77 s],
NDCG: [ 0.7457147   0.73377678  0.72917229  0.73030934  0.73518456  0.74271284
  0.75315035  0.76490761  0.77850463  0.79372469]
Iteration 12 [83.6 s]: rank_loss = 0.381383 [21.52 s],
NDCG: [ 0.75113231  0.73917216  0.73381702  0.73438542  0.73850365  0.74664707
  0.75681055  0.76845963  0.78169053  0.79663023]
Iteration 13 [74.5 s]: rank_loss = 0.305062 [27.19 s],
NDCG: [ 0.72997186  0.7201063   0.71798492  0.72062531  0.7260422   0.73472343
  0.74589877  0.75815781  0.7721893   0.7876068 ]
Iteration 13 [84.3 s]: rank_loss = 0.381315 [26.82 s],
NDCG: [ 0.73547814  0.72373752  0.72191136  0.7234463   0.7292981   0.73745057
  0.74842321  0.7605698   0.77428747  0.78978265]
Iteration 14 [70.2 s]: rank_loss = 0.305190 [20.59 s],
NDCG: [ 0.7007482   0.69836618  0.70038783  0.7052598   0.71288234  0.72313857
  0.7350679   0.74872682  0.7634247   0.77931207]
Iteration 14 [81.0 s]: rank_loss = 0.382049 [21.92 s],
NDCG: [ 0.70039698  0.69701998  0.69920241  0.70369077  0.71181644  0.72237397
  0.73448344  0.74802484  0.762831    0.77887448]
Iteration 15 [121.7 s]: rank_loss = 0.305306 [25.40 s],
NDCG: [ 0.68084578  0.68349751  0.68897206  0.69583626  0.70453002  0.71591946
  0.72839045  0.74259461  0.75795107  0.77417597]
Iteration 15 [81.4 s]: rank_loss = 0.380919 [20.55 s],
NDCG: [ 0.64991791  0.65922879  0.66749788  0.67766115  0.68894415  0.70197801
  0.71587328  0.73108722  0.74696057  0.76387683]
Iteration 16 [70.5 s]: rank_loss = 0.304914 [20.62 s],
NDCG: [ 0.61867466  0.63972397  0.65401552  0.66724272  0.67973857  0.69412852
  0.7084327   0.72441199  0.74105404  0.75813962]
Iteration 16 [82.8 s]: rank_loss = 0.381363 [21.36 s],
NDCG: [ 0.61733582  0.63637771  0.6493897   0.66235864  0.67532149  0.69001535
  0.70495136  0.72100897  0.7374565   0.75499042]
Iteration 17 [71.7 s]: rank_loss = 0.305091 [21.39 s],
NDCG: [ 0.6025498   0.62626473  0.64323867  0.65748894  0.67175981  0.68604238
  0.70152058  0.71768264  0.73470473  0.75245995]
Iteration 17 [83.4 s]: rank_loss = 0.381117 [21.37 s],
NDCG: [ 0.60714895  0.62729354  0.6409854   0.65470858  0.66919982  0.68374895
  0.69939089  0.71566055  0.7323927   0.75051875]
Iteration 18 [71.9 s]: rank_loss = 0.305153 [21.42 s],
NDCG: [ 0.59386275  0.6209636   0.63792744  0.65343515  0.66784204  0.68251684
  0.69836237  0.71472337  0.73185748  0.74996762]
Iteration 18 [82.9 s]: rank_loss = 0.381064 [21.42 s],
NDCG: [ 0.5872698   0.61082698  0.6272518   0.64254792  0.65701136  0.67289431
  0.68885067  0.7059918   0.72379673  0.74263992]
Iteration 19 [71.8 s]: rank_loss = 0.304922 [21.42 s],
NDCG: [ 0.57394744  0.60160371  0.62089346  0.63782806  0.65428632  0.67042422
  0.68756193  0.70408427  0.72227752  0.74095803]
Iteration 19 [83.1 s]: rank_loss = 0.380776 [21.47 s],
NDCG: [ 0.58488171  0.60838878  0.62575538  0.64179923  0.65669501  0.67244191
  0.68906304  0.70594839  0.72370386  0.74209823]
End. Best Iteration 2.

7. Alternate update for rank_u and rank_i with rating initialization and regularization
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000 --reg_layers [0.000001,0.0001,0.0002,0.0005]
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0.000001,0.0001,0.0002,0.0005]', verbose=1) 
Load data done [601.7 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [31.7], Init: 
Init_NDCG: [ 0.56535715  0.56594318  0.57417508  0.58413028  0.59619794  0.61107786
  0.6273972   0.64572149  0.66628677  0.68825514]
RatingInit_NDCG: [ 0.56426487  0.56788476  0.57429753  0.58548202  0.59729676  0.61237245
  0.62916898  0.64776905  0.6679594   0.68965513]
Iteration 0 [75.3 s]: rank_loss = 0.643475 [29.02 s],
NDCG: [ 0.75931389  0.74508887  0.74015665  0.74093721  0.74579108  0.75300197
  0.76296669  0.77457406  0.78762074  0.80182969]
Iteration 0 [228.9 s]: rank_loss = 0.695537 [31.51 s],
NDCG: [ 0.6023504   0.60290963  0.60856312  0.61612501  0.62670068  0.63970305
  0.65486013  0.67125274  0.69008105  0.71064432]
Iteration 1 [97.9 s]: rank_loss = 0.642677 [32.71 s],
NDCG: [ 0.758566    0.74402211  0.74092557  0.74100418  0.74554478  0.75282319
  0.76280683  0.77456186  0.78790087  0.80196738]
Iteration 1 [320.3 s]: rank_loss = 0.694697 [31.47 s],
NDCG: [ 0.72209371  0.7120375   0.70810687  0.71053945  0.7153037   0.72360327
  0.73542715  0.74814713  0.76332747  0.7791877 ]
Iteration 2 [156.5 s]: rank_loss = 0.634458 [32.08 s],
NDCG: [ 0.75748939  0.74514331  0.74012691  0.74098283  0.74499811  0.75264987
  0.76271204  0.77441344  0.78756909  0.80163019]
Iteration 2 [360.0 s]: rank_loss = 0.694237 [31.86 s],
NDCG: [ 0.40662329  0.42846796  0.44456917  0.46316536  0.48252157  0.50283199
  0.52461091  0.54801163  0.57369767  0.60185274]
Iteration 3 [260.7 s]: rank_loss = 0.638091 [31.68 s],
NDCG: [ 0.75559186  0.74203096  0.73725217  0.73839486  0.74372566  0.75124998
  0.76155745  0.77314126  0.78649658  0.80107581]
Iteration 3 [411.7 s]: rank_loss = 0.694037 [31.51 s],
NDCG: [ 0.71688124  0.70391148  0.69974676  0.7019055   0.70785916  0.71590929
  0.72721169  0.74110262  0.75597013  0.77280024]
Iteration 4 [420.7 s]: rank_loss = 0.647603 [33.86 s],
NDCG: [ 0.7543168   0.74352772  0.73947257  0.73969745  0.74448109  0.75163021
  0.76206147  0.77357791  0.78708675  0.80125141]
Iteration 4 [412.7 s]: rank_loss = 0.693941 [33.51 s],
NDCG: [ 0.71109255  0.69847769  0.69485015  0.69500887  0.69954039  0.70722421
  0.71844875  0.73184986  0.74687251  0.76441179]
Iteration 5 [411.8 s]: rank_loss = 0.657400 [33.50 s],
NDCG: [ 0.754441    0.74317791  0.73913613  0.73941977  0.74336378  0.75085855
  0.76091183  0.77253376  0.78605558  0.80052669]
Iteration 5 [408.2 s]: rank_loss = 0.693894 [31.19 s],
NDCG: [ 0.69028867  0.67205095  0.66315587  0.6620679   0.66612019  0.67487992
  0.68734563  0.70276883  0.72018621  0.73921412]
Iteration 6 [393.2 s]: rank_loss = 0.661227 [30.95 s],
NDCG: [ 0.75495604  0.7423235   0.73852408  0.7392126   0.74317148  0.75103629
  0.76107967  0.77303383  0.7859484   0.80016946]

8. exp2 but after MLP merge 3 latent instead of 4.
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [353.2 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [32.0], Init: 
Init_NDCG: [ 0.57601257  0.57752515  0.58391182  0.59252204  0.60520883  0.61877088
  0.63458411  0.65321411  0.6728387   0.6942912 ]
RatingInit_NDCG: [ 0.5670817   0.57120638  0.5778615   0.58724099  0.59968605  0.61474995
  0.63153139  0.64922564  0.66893534  0.69065768]
Iteration 0 [76.1 s]: rank_loss = 0.630080 [28.19 s],
NDCG: [ 0.74286152  0.73543546  0.73350802  0.73457329  0.74041005  0.74836464
  0.75918529  0.77100179  0.78423251  0.79871047]
Iteration 0 [79.9 s]: rank_loss = 0.659022 [28.28 s],
NDCG: [ 0.54388672  0.54780026  0.55515045  0.56494261  0.57621058  0.58998314
  0.60639726  0.62564637  0.64742319  0.67074619]
Iteration 1 [74.9 s]: rank_loss = 0.619317 [28.58 s],
NDCG: [ 0.75502867  0.74166131  0.73783687  0.73914884  0.74399108  0.7516362
  0.76167388  0.77363585  0.7869816   0.80120737]
Iteration 1 [87.0 s]: rank_loss = 0.645884 [28.31 s],
NDCG: [ 0.75048423  0.7385576   0.73540674  0.73616959  0.74168263  0.7495447
  0.75966027  0.77148882  0.78503994  0.79922109]
Iteration 2 [75.3 s]: rank_loss = 0.615612 [28.40 s],
NDCG: [ 0.75796135  0.74430867  0.73957334  0.73994948  0.74454056  0.75243028
  0.76266591  0.77476075  0.78786247  0.80192476]
Iteration 2 [88.0 s]: rank_loss = 0.643642 [28.58 s],
NDCG: [ 0.75652369  0.74148508  0.73658908  0.73638988  0.74142911  0.74988646
  0.7606509   0.77250626  0.78568673  0.80012406]
Iteration 3 [75.6 s]: rank_loss = 0.615478 [28.16 s],
NDCG: [ 0.75992168  0.74544134  0.74119633  0.74147847  0.74583526  0.75343381
  0.76387862  0.77535083  0.78838486  0.80251403]
Iteration 3 [88.0 s]: rank_loss = 0.642787 [28.14 s],
NDCG: [ 0.75719778  0.74211794  0.73713746  0.73754414  0.74195262  0.74988537
  0.76031388  0.7721064   0.7852436   0.79975824]
Iteration 4 [75.6 s]: rank_loss = 0.615127 [28.12 s],
NDCG: [ 0.75828099  0.74414063  0.73959837  0.74101233  0.74536077  0.75277401
  0.76286499  0.77456299  0.78764262  0.80185239]
Iteration 4 [89.2 s]: rank_loss = 0.642453 [28.10 s],
NDCG: [ 0.75347211  0.74054379  0.73578546  0.7366168   0.7411729   0.7492758
  0.75943934  0.77174178  0.784892    0.79904522]
Iteration 5 [75.7 s]: rank_loss = 0.614544 [28.11 s],
NDCG: [ 0.7601204   0.74493446  0.7400094   0.74075933  0.74462388  0.75296442
  0.76265699  0.77442789  0.78761035  0.80205648]
Iteration 5 [89.8 s]: rank_loss = 0.641694 [28.89 s],
NDCG: [ 0.75649957  0.74201222  0.73735051  0.73786859  0.74211777  0.74972063
  0.75993634  0.77224681  0.78549143  0.79975062]
Iteration 6 [77.3 s]: rank_loss = 0.614251 [28.91 s],
NDCG: [ 0.75797065  0.74459966  0.74034066  0.74038032  0.74476478  0.75279137
  0.76256539  0.77467053  0.78795034  0.80187184]
Iteration 6 [89.7 s]: rank_loss = 0.642099 [28.96 s],
NDCG: [ 0.75908247  0.74315359  0.73867147  0.73843725  0.74337852  0.75102429
  0.76074132  0.77243636  0.78609855  0.8002621 ]
Iteration 7 [77.1 s]: rank_loss = 0.613942 [28.54 s],
NDCG: [ 0.7616647   0.74414137  0.74033105  0.740527    0.74523055  0.75264637
  0.76294733  0.77497742  0.78794097  0.80221867]
Iteration 7 [89.9 s]: rank_loss = 0.641654 [28.77 s],
NDCG: [ 0.7577364   0.74235391  0.73792032  0.73828497  0.74296059  0.75082281
  0.76053585  0.77242828  0.78592343  0.80061608]
Iteration 8 [76.5 s]: rank_loss = 0.613554 [28.24 s],
NDCG: [ 0.76088572  0.74487563  0.7401696   0.74090057  0.74536645  0.75306601
  0.76267825  0.77473944  0.78800599  0.80221189]
Iteration 8 [88.6 s]: rank_loss = 0.641814 [28.11 s],
NDCG: [ 0.75996018  0.74504204  0.73983471  0.74011173  0.74495393  0.75248485
  0.76184615  0.77390364  0.78746099  0.80181124]
Iteration 9 [75.8 s]: rank_loss = 0.613536 [27.94 s],
NDCG: [ 0.75884067  0.74474714  0.74028034  0.74063295  0.74503373  0.75242844
  0.76253134  0.77464274  0.78779885  0.80190286]
Iteration 9 [88.3 s]: rank_loss = 0.641327 [28.07 s],
NDCG: [ 0.75669469  0.74430475  0.7396431   0.73964398  0.74434275  0.75140802
  0.76168682  0.77339635  0.78678177  0.80099958]
Iteration 10 [75.7 s]: rank_loss = 0.613675 [28.07 s],
NDCG: [ 0.76140394  0.74712513  0.74116765  0.74120398  0.74595129  0.75389045
  0.76429699  0.77562123  0.78869845  0.80304955]
Iteration 10 [89.3 s]: rank_loss = 0.641283 [27.50 s],
NDCG: [ 0.75908656  0.74391019  0.73824483  0.73945538  0.74336485  0.75123408
  0.76161074  0.77344292  0.78688588  0.80113012]
Iteration 11 [75.3 s]: rank_loss = 0.613768 [27.96 s],
NDCG: [ 0.7581112   0.74384685  0.7391754   0.74000781  0.74545024  0.75285052
  0.76258114  0.77421903  0.78739496  0.80155878]
Iteration 11 [88.2 s]: rank_loss = 0.641382 [27.33 s],
NDCG: [ 0.75901927  0.74478833  0.73919783  0.73995603  0.74450373  0.75200839
  0.76207451  0.7738878   0.78683345  0.80106505]
Iteration 12 [76.3 s]: rank_loss = 0.613495 [28.07 s],
NDCG: [ 0.75986194  0.7448863   0.7405701   0.74149327  0.74532504  0.7528245
  0.76370422  0.77517577  0.78793464  0.80223503]
Iteration 12 [89.2 s]: rank_loss = 0.641075 [28.13 s],
NDCG: [ 0.7604342   0.74364524  0.73939772  0.74013437  0.74462423  0.75201108
  0.7619071   0.77379707  0.78696072  0.80149929]
Iteration 13 [76.1 s]: rank_loss = 0.613406 [27.90 s],
NDCG: [ 0.75736268  0.74498856  0.7402052   0.74053143  0.7453334   0.75264096
  0.76287436  0.77437889  0.78771735  0.80173383]
Iteration 13 [89.0 s]: rank_loss = 0.641671 [28.04 s],
NDCG: [ 0.76058149  0.74327531  0.73841836  0.73947064  0.74387196  0.75120495
  0.76154511  0.77308519  0.78635768  0.8008054 ]
Iteration 14 [75.8 s]: rank_loss = 0.612936 [26.89 s],
NDCG: [ 0.75743769  0.74451883  0.73930708  0.73965997  0.74461041  0.75238255
  0.7623691   0.77379487  0.78723646  0.80152658]
Iteration 14 [89.0 s]: rank_loss = 0.641113 [28.13 s],
NDCG: [ 0.75873485  0.74302928  0.73771374  0.73754603  0.74195596  0.74951173
  0.75961602  0.7711618   0.78475808  0.79927727]
Iteration 15 [76.1 s]: rank_loss = 0.613128 [28.10 s],
NDCG: [ 0.75806511  0.74329881  0.73882424  0.73940228  0.74431997  0.75172141
  0.76218251  0.77347244  0.78680046  0.80114889]
Iteration 15 [88.2 s]: rank_loss = 0.641192 [28.13 s],
NDCG: [ 0.75795286  0.74299148  0.73908425  0.73990544  0.74437816  0.75195511
  0.76195514  0.77347392  0.78676332  0.80110844]
Iteration 16 [75.8 s]: rank_loss = 0.613189 [27.98 s],
NDCG: [ 0.75670287  0.74408876  0.73870883  0.74037086  0.74521172  0.75227903
  0.76234677  0.77400794  0.78728915  0.80129068]
Iteration 16 [89.3 s]: rank_loss = 0.640788 [28.24 s],
NDCG: [ 0.7555442   0.74226816  0.73773792  0.73872253  0.74390314  0.75090324
  0.76113064  0.77277665  0.78605039  0.80010586]
Iteration 17 [75.2 s]: rank_loss = 0.612375 [28.13 s],
NDCG: [ 0.75553962  0.74284682  0.73851273  0.73996241  0.74437802  0.75182877
  0.76179135  0.77365789  0.78677737  0.80095815]
Iteration 17 [88.2 s]: rank_loss = 0.641066 [27.14 s],
NDCG: [ 0.75316285  0.74112486  0.73685781  0.73733499  0.74139536  0.74882177
  0.7587293   0.77094332  0.78417003  0.7987991 ]
Iteration 18 [76.0 s]: rank_loss = 0.613004 [27.97 s],
NDCG: [ 0.7540079   0.74175479  0.73707967  0.73819814  0.74300777  0.75078138
  0.76054242  0.77221264  0.7854824   0.80021652]
Iteration 18 [89.1 s]: rank_loss = 0.640981 [27.84 s],
NDCG: [ 0.75345801  0.73940504  0.73417734  0.73495582  0.73984145  0.74711049
  0.75722658  0.76917439  0.78228661  0.79706007]
Iteration 19 [75.5 s]: rank_loss = 0.612725 [27.21 s],
NDCG: [ 0.75408776  0.74121598  0.7360158   0.73639183  0.74166466  0.74938177
  0.75949835  0.77117498  0.78458742  0.79919587]
Iteration 19 [89.2 s]: rank_loss = 0.641122 [28.07 s],
NDCG: [ 0.75423586  0.74048667  0.73497892  0.73573703  0.74027189  0.74768457
  0.75804487  0.76978858  0.78343682  0.79804204]
End. Best Iteration 10.


9. exp2 but MLP [128,32,8]
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000 --layers [128,32,8] --reg_layers [0,0,0]
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[128,32,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0]', verbose=1) 
Load data done [359.2 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [32.4], Init: 
Init_NDCG: [ 0.55764712  0.56491616  0.57346638  0.58446753  0.59713149  0.61146261
  0.62808949  0.64621693  0.6660614   0.68846221]
RatingInit_NDCG: [ 0.56282972  0.56835314  0.57580579  0.58538524  0.59859216  0.61331296
  0.62981814  0.64819742  0.66824892  0.68994913]
Iteration 0 [142.9 s]: rank_loss = 0.633613 [29.39 s],
NDCG: [ 0.75254405  0.74110228  0.73715261  0.73800002  0.7428265   0.75049526
  0.7607885   0.77268874  0.78631538  0.80051447]
Iteration 0 [155.7 s]: rank_loss = 0.653154 [29.68 s],
NDCG: [ 0.73692825  0.72810886  0.72447228  0.72704839  0.73216427  0.74068581
  0.75116332  0.76361236  0.77745665  0.79247147]
Iteration 1 [149.5 s]: rank_loss = 0.616933 [29.02 s],
NDCG: [ 0.76057143  0.74660013  0.74136117  0.74148448  0.74597342  0.75312901
  0.76280201  0.77467811  0.78775825  0.80219009]
Iteration 1 [179.4 s]: rank_loss = 0.643973 [28.42 s],
NDCG: [ 0.75475763  0.74171442  0.73723802  0.73735363  0.74258065  0.75087745
  0.76094928  0.77250027  0.78562835  0.80003451]
Iteration 2 [145.9 s]: rank_loss = 0.615442 [28.31 s],
NDCG: [ 0.76106948  0.7463998   0.74139829  0.741461    0.74575309  0.75337111
  0.76312029  0.77501822  0.78819637  0.80245846]
Iteration 2 [174.6 s]: rank_loss = 0.643046 [28.48 s],
NDCG: [ 0.7572193   0.74138477  0.73674831  0.73715554  0.7421811   0.74976006
  0.7598641   0.77192477  0.78558759  0.79982399]
Iteration 3 [146.7 s]: rank_loss = 0.615072 [28.21 s],
NDCG: [ 0.76166838  0.7455932   0.74116894  0.74157101  0.74592707  0.75336334
  0.76361624  0.77523487  0.78827369  0.80260792]
Iteration 3 [174.4 s]: rank_loss = 0.642457 [27.55 s],
NDCG: [ 0.75612437  0.74010797  0.73657889  0.73758775  0.74190618  0.74952087
  0.75936322  0.77126568  0.78505404  0.7995455 ]
Iteration 4 [147.0 s]: rank_loss = 0.614602 [28.13 s],
NDCG: [ 0.7590411   0.74516605  0.74085687  0.74153806  0.74600988  0.75330889
  0.7633288   0.77538534  0.78869599  0.80250956]
Iteration 4 [175.6 s]: rank_loss = 0.642580 [27.98 s],
NDCG: [ 0.75604585  0.74220214  0.73861409  0.73891018  0.74326847  0.75107123
  0.76108839  0.77296238  0.78649077  0.80067681]
Iteration 5 [147.1 s]: rank_loss = 0.614516 [27.57 s],
NDCG: [ 0.76102672  0.74662526  0.74202121  0.74241082  0.74668597  0.75444131
  0.7640385   0.77571425  0.78876861  0.80311708]
Iteration 5 [177.2 s]: rank_loss = 0.641983 [28.27 s],
NDCG: [ 0.75603421  0.74375806  0.73926373  0.74000325  0.74416656  0.75179994
  0.76178131  0.77367971  0.787143    0.80127883]
Iteration 6 [147.9 s]: rank_loss = 0.614449 [28.20 s],
NDCG: [ 0.7599303   0.74577996  0.74181863  0.74199674  0.74609851  0.75391315
  0.76381304  0.77578878  0.78853985  0.80284907]
Iteration 6 [177.1 s]: rank_loss = 0.642198 [28.23 s],
NDCG: [ 0.75851192  0.74446268  0.73933323  0.7399983   0.74418888  0.75179523
  0.76189881  0.77368978  0.78706572  0.80115928]
Iteration 7 [146.3 s]: rank_loss = 0.613966 [28.02 s],
NDCG: [ 0.75958034  0.74581419  0.74205287  0.74250307  0.74641206  0.75432911
  0.76421628  0.77589685  0.78894313  0.8031664 ]
Iteration 7 [175.5 s]: rank_loss = 0.641430 [28.16 s],
NDCG: [ 0.75887463  0.7435971   0.73953784  0.74000403  0.74486669  0.75262366
  0.76251087  0.7743684   0.78765507  0.80200871]
Iteration 8 [147.2 s]: rank_loss = 0.613836 [28.22 s],
NDCG: [ 0.76033875  0.74640818  0.74201398  0.74220723  0.74668432  0.75469504
  0.76403655  0.77585741  0.78888139  0.80319781]
Iteration 8 [175.3 s]: rank_loss = 0.641982 [28.20 s],
NDCG: [ 0.75915649  0.74557456  0.74079609  0.74059852  0.7457002   0.75276116
  0.7629335   0.77465457  0.78793668  0.80231514]
Iteration 9 [146.8 s]: rank_loss = 0.613511 [28.12 s],
NDCG: [ 0.75916278  0.74496272  0.74097427  0.74176417  0.74640457  0.75406353
  0.76384853  0.77580643  0.78887311  0.8030279 ]
Iteration 9 [175.6 s]: rank_loss = 0.641644 [27.21 s],
NDCG: [ 0.75955946  0.74465922  0.73964319  0.74005408  0.74532768  0.75264578
  0.76312736  0.7747937   0.7879515   0.80208684]
Iteration 10 [147.5 s]: rank_loss = 0.613885 [28.42 s],
NDCG: [ 0.76050571  0.74600416  0.74241735  0.74213472  0.74686362  0.75457358
  0.76431173  0.77634565  0.78902352  0.80322585]
Iteration 10 [175.5 s]: rank_loss = 0.641469 [28.19 s],
NDCG: [ 0.75944451  0.74387035  0.74051801  0.74068881  0.7455579   0.75319497
  0.76355159  0.77513747  0.78827981  0.80229069]
Iteration 11 [146.5 s]: rank_loss = 0.613360 [28.69 s],
NDCG: [ 0.7614622   0.74660844  0.74301531  0.74213595  0.74694547  0.75426022
  0.76446289  0.77616141  0.78923008  0.80344924]
Iteration 11 [178.7 s]: rank_loss = 0.641431 [28.94 s],
NDCG: [ 0.76001551  0.74575294  0.74232535  0.74269153  0.7464912   0.75373218
  0.76383709  0.77571566  0.78890408  0.80290956]
Iteration 12 [149.9 s]: rank_loss = 0.612929 [28.87 s],
NDCG: [ 0.76269068  0.74652048  0.74342657  0.74283974  0.74734335  0.75539561
  0.76523179  0.77681589  0.78981543  0.80386747]
Iteration 12 [177.8 s]: rank_loss = 0.641064 [28.94 s],
NDCG: [ 0.76155622  0.74517864  0.74172602  0.74191964  0.74616387  0.75413201
  0.76381977  0.77582539  0.78879492  0.80283344]
Iteration 13 [148.5 s]: rank_loss = 0.613080 [28.25 s],
NDCG: [ 0.76297901  0.74705381  0.74350738  0.74336261  0.74783243  0.75524161
  0.76484313  0.77645116  0.78969371  0.80360241]
Iteration 13 [175.0 s]: rank_loss = 0.641150 [28.11 s],
NDCG: [ 0.76069531  0.74543227  0.74170534  0.74262302  0.74645967  0.75381304
  0.76348471  0.77558463  0.78867407  0.80281417]
Iteration 14 [148.1 s]: rank_loss = 0.613193 [28.18 s],
NDCG: [ 0.76148421  0.74651922  0.74182376  0.74295     0.74724437  0.75470818
  0.76478728  0.77649485  0.7893876   0.80320065]
Iteration 14 [176.0 s]: rank_loss = 0.641447 [28.19 s],
NDCG: [ 0.76073367  0.74478796  0.74048416  0.74196167  0.74615106  0.75375804
  0.76400114  0.77580215  0.78850288  0.80277439]
Iteration 15 [148.0 s]: rank_loss = 0.613510 [28.19 s],
NDCG: [ 0.76030133  0.74563723  0.74207682  0.74267654  0.74724159  0.75478238
  0.76461806  0.77613649  0.78938342  0.80332588]
Iteration 15 [176.5 s]: rank_loss = 0.641044 [28.23 s],
NDCG: [ 0.75996112  0.7451633   0.74150521  0.74207923  0.74653027  0.75405386
  0.76396456  0.77540865  0.78890051  0.80292839]
Iteration 16 [148.9 s]: rank_loss = 0.613157 [28.34 s],
NDCG: [ 0.76281205  0.74700944  0.74227918  0.74270817  0.74745426  0.75480495
  0.76486054  0.77697313  0.78979385  0.80370852]
Iteration 16 [176.6 s]: rank_loss = 0.641288 [28.21 s],
NDCG: [ 0.75965536  0.74606664  0.7417181   0.74214253  0.7466763   0.75404409
  0.76401084  0.77609655  0.78898466  0.80284846]
Iteration 17 [147.5 s]: rank_loss = 0.613044 [28.46 s],
NDCG: [ 0.7625822   0.74777283  0.74366956  0.74331481  0.74716827  0.75527978
  0.7652101   0.77696026  0.79024903  0.80385844]
Iteration 17 [176.3 s]: rank_loss = 0.641362 [28.10 s],
NDCG: [ 0.76121758  0.74598613  0.74200939  0.74230725  0.74638079  0.75456405
  0.76443854  0.77631702  0.78955207  0.80355432]
Iteration 18 [147.4 s]: rank_loss = 0.613071 [28.34 s],
NDCG: [ 0.7617782   0.74655878  0.74270642  0.74324962  0.74733265  0.75511793
  0.7653678   0.7767256   0.78999897  0.80399277]
Iteration 18 [176.7 s]: rank_loss = 0.640842 [28.27 s],
NDCG: [ 0.75969385  0.7448793   0.74183324  0.74257008  0.74664152  0.75412642
  0.76437533  0.77614051  0.78939542  0.80352345]
Iteration 19 [148.5 s]: rank_loss = 0.612842 [28.36 s],
NDCG: [ 0.76143956  0.74675247  0.74321135  0.74309776  0.74733938  0.75539238
  0.76492724  0.77650516  0.789776    0.80378069]
Iteration 19 [176.8 s]: rank_loss = 0.640933 [28.26 s],
NDCG: [ 0.75963506  0.74596975  0.74192779  0.74232151  0.74672187  0.75474944
  0.76456977  0.77590967  0.78931123  0.80314404]
End. Best Iteration 18.

liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000 --layers [512,128,32,8] --reg_layers [0,0,0,0]
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[512,128,32,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [347.2 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [38.1], Init: 
Init_NDCG: [ 0.56197946  0.56777405  0.57550045  0.58643256  0.59866374  0.61322165
  0.62943925  0.64803778  0.66797423  0.68985301]
RatingInit_NDCG: [ 0.57474537  0.57484139  0.58128377  0.58937278  0.60106233  0.61510655
  0.63135344  0.64928441  0.66933705  0.69134976]
Iteration 0 [562.6 s]: rank_loss = 0.627098 [35.06 s],
NDCG: [ 0.75390351  0.74232738  0.73751228  0.73776971  0.74260898  0.75055151
  0.76014612  0.77200803  0.78560968  0.80017693]
Iteration 0 [586.7 s]: rank_loss = 0.651413 [33.80 s],
NDCG: [ 0.73652973  0.72624398  0.72198367  0.72292427  0.72765731  0.73604134
  0.74607502  0.75824043  0.77248341  0.78771677]
Iteration 1 [595.5 s]: rank_loss = 0.617969 [37.05 s],
NDCG: [ 0.75698379  0.74328729  0.73933209  0.739722    0.74427807  0.75229531
  0.76247355  0.77406964  0.78728816  0.80113044]
Iteration 1 [707.0 s]: rank_loss = 0.643739 [41.07 s],
NDCG: [ 0.75373354  0.74056955  0.73588042  0.73591648  0.74076916  0.74883448
  0.75865831  0.77051091  0.78406     0.79860288]
Iteration 2 [635.1 s]: rank_loss = 0.615998 [37.57 s],
NDCG: [ 0.76118268  0.74580481  0.74066328  0.74098537  0.74552452  0.75337372
  0.76357431  0.77500364  0.78826644  0.8023413 ]
Iteration 2 [747.5 s]: rank_loss = 0.643229 [39.72 s],
NDCG: [ 0.75733218  0.74255862  0.73768487  0.73852263  0.74320622  0.75066699
  0.7607738   0.77281589  0.7862681   0.80060683]
Iteration 3 [646.8 s]: rank_loss = 0.615526 [43.03 s],
NDCG: [ 0.759514    0.74552567  0.74056747  0.74070414  0.74566782  0.75318164
  0.76325336  0.77541723  0.78857104  0.8029153 ]
Iteration 3 [717.2 s]: rank_loss = 0.642669 [34.34 s],
NDCG: [ 0.7574787   0.74235219  0.73809267  0.73842331  0.7432609   0.75085429
  0.76097484  0.77324381  0.78646899  0.80076302]
Iteration 4 [582.2 s]: rank_loss = 0.614662 [34.18 s],
NDCG: [ 0.75750228  0.74437777  0.74076687  0.74121846  0.74597185  0.75333289
  0.76335554  0.77520194  0.78859544  0.80279514]
Iteration 4 [701.9 s]: rank_loss = 0.642200 [34.58 s],
NDCG: [ 0.75725703  0.74283979  0.73920497  0.74009864  0.74479877  0.75255852
  0.76246003  0.77425591  0.78779807  0.80188635]
Iteration 5 [585.0 s]: rank_loss = 0.614559 [37.61 s],
NDCG: [ 0.76006614  0.74549868  0.7425009   0.74197541  0.74639951  0.75422829
  0.76387025  0.77605538  0.7889558   0.80312418]
Iteration 5 [722.8 s]: rank_loss = 0.641643 [34.98 s],
NDCG: [ 0.75777741  0.74385233  0.74026546  0.73993176  0.74476731  0.75243434
  0.76286991  0.77477955  0.78790401  0.80198006]
Iteration 6 [599.9 s]: rank_loss = 0.614231 [37.05 s],
NDCG: [ 0.76204987  0.7471625   0.74222777  0.74200726  0.74635034  0.75393665
  0.76386653  0.7758326   0.78895528  0.80309547]
Iteration 6 [730.0 s]: rank_loss = 0.641526 [35.63 s],
NDCG: [ 0.7578425   0.74388481  0.74034757  0.7396025   0.74434492  0.75189141
  0.76218612  0.77437182  0.78745831  0.80182052]
Iteration 7 [592.3 s]: rank_loss = 0.613843 [34.45 s],
NDCG: [ 0.76050068  0.74676374  0.74214028  0.74235952  0.74645389  0.75439664
  0.76417104  0.7760064   0.78916523  0.8032627 ]
Iteration 7 [769.2 s]: rank_loss = 0.641681 [42.99 s],
NDCG: [ 0.75751517  0.74411721  0.74002508  0.74046239  0.74467536  0.75272005
  0.76294306  0.7748658   0.78798103  0.80212756]
Iteration 8 [653.1 s]: rank_loss = 0.613363 [40.36 s],
NDCG: [ 0.76011173  0.74634169  0.74206407  0.74269075  0.74692339  0.75446368
  0.76473776  0.77670922  0.78968867  0.80360975]
Iteration 8 [771.7 s]: rank_loss = 0.640966 [39.86 s],
NDCG: [ 0.75786594  0.74504654  0.74014171  0.74052761  0.74538246  0.75344193
  0.76338405  0.77514709  0.78828349  0.802419  ]
Iteration 9 [646.1 s]: rank_loss = 0.613639 [39.99 s],
NDCG: [ 0.7617716   0.7468605   0.74301901  0.74227896  0.7466797   0.75480372
  0.76477463  0.77667638  0.7896449   0.80374674]
Iteration 9 [771.3 s]: rank_loss = 0.641029 [40.19 s],
NDCG: [ 0.76049439  0.7459626   0.74164408  0.74139892  0.74555388  0.75322106
  0.76325311  0.77451192  0.7874452   0.80207235]
Iteration 10 [646.5 s]: rank_loss = 0.613361 [43.79 s],
NDCG: [ 0.76283217  0.74775694  0.74272708  0.74285284  0.74728863  0.75523775
  0.76514276  0.77705411  0.79002122  0.80406746]
Iteration 10 [770.4 s]: rank_loss = 0.640997 [40.95 s],
NDCG: [ 0.76137259  0.74621462  0.74200515  0.74142872  0.74590927  0.75370555
  0.76410458  0.775847    0.78851215  0.80304518]
Iteration 11 [633.4 s]: rank_loss = 0.613233 [38.58 s],
NDCG: [ 0.76478635  0.74800987  0.74365862  0.74401291  0.74744296  0.75523766
  0.76518914  0.77676661  0.78970006  0.80389424]
Iteration 11 [759.1 s]: rank_loss = 0.640942 [39.45 s],
NDCG: [ 0.76282494  0.74670563  0.7421473   0.74253044  0.7464967   0.75401618
  0.76438242  0.77604789  0.78912391  0.80299626]
Iteration 12 [631.7 s]: rank_loss = 0.613120 [37.65 s],
NDCG: [ 0.76259792  0.74736361  0.74351298  0.74334617  0.74768302  0.75532562
  0.76533192  0.77694372  0.78962173  0.80386787]
Iteration 12 [744.6 s]: rank_loss = 0.640902 [38.41 s],
NDCG: [ 0.76022587  0.74532831  0.74184578  0.74199021  0.7463757   0.75409012
  0.76425905  0.7757819   0.78857928  0.80288963]
Iteration 13 [631.2 s]: rank_loss = 0.613363 [39.08 s],
NDCG: [ 0.7618216   0.74659616  0.74247058  0.74230557  0.74696038  0.75436561
  0.76459175  0.77632228  0.78946724  0.80349157]
Iteration 13 [749.9 s]: rank_loss = 0.641020 [38.60 s],
NDCG: [ 0.76077598  0.74467526  0.74009085  0.740532    0.74549698  0.75229728
  0.76223304  0.77361214  0.7869536   0.80155851]
Iteration 14 [639.1 s]: rank_loss = 0.612604 [41.24 s],
NDCG: [ 0.76066468  0.74546135  0.74219641  0.74190974  0.74646692  0.75454195
  0.76452263  0.77633203  0.78956543  0.80326684]
Iteration 14 [760.4 s]: rank_loss = 0.641014 [38.66 s],
NDCG: [ 0.76066405  0.74477368  0.74077977  0.74082193  0.74598544  0.75389571
  0.76421687  0.77566633  0.78880273  0.80290207]
Iteration 15 [653.6 s]: rank_loss = 0.612990 [38.00 s],
NDCG: [ 0.76377766  0.747961    0.74463917  0.74421363  0.74816894  0.75557931
  0.76570165  0.77722066  0.7903106   0.80419774]
Iteration 15 [756.6 s]: rank_loss = 0.640683 [44.63 s],
NDCG: [ 0.76034962  0.74659152  0.74305497  0.74265601  0.7471636   0.75465269
  0.76491161  0.77628218  0.7894228   0.80337493]
Iteration 16 [644.7 s]: rank_loss = 0.612897 [37.92 s],
NDCG: [ 0.7629004   0.74767491  0.74400879  0.74338755  0.74814978  0.75553643
  0.76524942  0.77715884  0.78992844  0.80398194]
Iteration 16 [767.0 s]: rank_loss = 0.640644 [40.71 s],
NDCG: [ 0.76149553  0.74659649  0.74298451  0.74215273  0.74705918  0.75484297
  0.76495215  0.77628442  0.78939085  0.8034005 ]
Iteration 17 [631.3 s]: rank_loss = 0.612489 [37.19 s],
NDCG: [ 0.76256697  0.74708567  0.74353253  0.74311966  0.74754272  0.75575921
  0.76526895  0.77689547  0.78997966  0.80417526]
Iteration 17 [746.9 s]: rank_loss = 0.640655 [37.66 s],
NDCG: [ 0.76144446  0.74559245  0.74178186  0.74206051  0.74645941  0.7542786
  0.76423214  0.77622262  0.78918912  0.80315155]
Iteration 18 [627.2 s]: rank_loss = 0.612215 [37.85 s],
NDCG: [ 0.76305133  0.7477609   0.74322865  0.74332978  0.74757881  0.75559237
  0.76531334  0.77685897  0.78980351  0.8039101 ]
Iteration 18 [765.3 s]: rank_loss = 0.640555 [38.41 s],
NDCG: [ 0.76149082  0.74624199  0.74217288  0.74232237  0.7471644   0.75546478
  0.76489346  0.7762815   0.78917554  0.80339462]
Iteration 19 [636.7 s]: rank_loss = 0.612272 [41.54 s],
NDCG: [ 0.76137133  0.74674729  0.74271274  0.7428323   0.74760151  0.75528645
  0.76526316  0.77657071  0.78941286  0.80344747]
Iteration 19 [748.6 s]: rank_loss = 0.640737 [38.49 s],
NDCG: [ 0.76212439  0.7460656   0.74193655  0.74220572  0.74678078  0.75489795
  0.76488973  0.77637281  0.78935555  0.80338607]
End. Best Iteration 15.

liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000 --layers [128,64,32,16,8] --reg_layers [0,0,0,0,0]
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[128,64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0,0]', verbose=1) 
Load data done [349.6 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [35.4], Init: 
Init_NDCG: [ 0.56695827  0.57140389  0.57650971  0.58652927  0.59868476  0.6131709
  0.62972893  0.64767388  0.66829185  0.69013846]
RatingInit_NDCG: [ 0.55967645  0.56674892  0.57480717  0.58506686  0.59783637  0.61217912
  0.62888073  0.64747125  0.66782623  0.68934781]
Iteration 0 [172.5 s]: rank_loss = 0.628788 [32.42 s],
NDCG: [ 0.75734413  0.7453968   0.74090967  0.74055942  0.74499387  0.75286251
  0.76239729  0.77445733  0.78726829  0.80195794]
Iteration 0 [182.3 s]: rank_loss = 0.652082 [31.70 s],
NDCG: [ 0.7325253   0.72221025  0.71934743  0.72138018  0.72663826  0.73487403
  0.74524654  0.75780674  0.77187332  0.78735513]
Iteration 1 [177.8 s]: rank_loss = 0.618217 [32.92 s],
NDCG: [ 0.76031611  0.74534341  0.74125512  0.74131203  0.74594848  0.7539018
  0.76353594  0.77509894  0.78803453  0.80244645]
Iteration 1 [200.8 s]: rank_loss = 0.644039 [31.25 s],
NDCG: [ 0.75119735  0.73576866  0.73215275  0.73296809  0.73810131  0.74628397
  0.75638985  0.76861378  0.78247386  0.79663025]
Iteration 2 [176.7 s]: rank_loss = 0.616502 [34.11 s],
NDCG: [ 0.76155244  0.74611765  0.74118349  0.7418573   0.74611725  0.75349127
  0.76402764  0.77550384  0.78865856  0.8028502 ]
Iteration 2 [214.3 s]: rank_loss = 0.642954 [32.66 s],
NDCG: [ 0.75782174  0.74372017  0.73776194  0.73841919  0.74295882  0.75101924
  0.76083079  0.77226348  0.78537216  0.80015736]
Iteration 3 [182.3 s]: rank_loss = 0.615434 [36.02 s],
NDCG: [ 0.76015544  0.74619762  0.74230551  0.74287292  0.74677325  0.75419786
  0.76439126  0.77589361  0.78913212  0.80330987]
Iteration 3 [211.2 s]: rank_loss = 0.642702 [33.45 s],
NDCG: [ 0.75854493  0.74384684  0.73937371  0.73999456  0.74422388  0.75163386
  0.76141565  0.77325925  0.78653038  0.8012963 ]
Iteration 4 [609.4 s]: rank_loss = 0.615241 [31.38 s],
NDCG: [ 0.7612748   0.74728125  0.74248589  0.74318051  0.7472109   0.75507502
  0.76499762  0.77666697  0.78965446  0.80348335]
Iteration 4 [208.2 s]: rank_loss = 0.642524 [26.02 s],
NDCG: [ 0.75712088  0.74300212  0.73768313  0.73800194  0.74277464  0.75057368
  0.76104196  0.77291927  0.78558069  0.80039631]
Iteration 5 [173.2 s]: rank_loss = 0.614687 [35.54 s],
NDCG: [ 0.76285135  0.74673774  0.74246329  0.74201511  0.74666805  0.75455385
  0.76482533  0.77634338  0.78944223  0.80360152]
Iteration 5 [193.0 s]: rank_loss = 0.642697 [27.49 s],
NDCG: [ 0.75801229  0.74309379  0.73773527  0.7383839   0.74372783  0.75166053
  0.76188796  0.77360025  0.78705845  0.8012787 ]
Iteration 6 [159.3 s]: rank_loss = 0.614350 [28.68 s],
NDCG: [ 0.76319188  0.74760361  0.7433212   0.74393377  0.74842279  0.75582608
  0.76542518  0.77706813  0.79002256  0.80428402]
Iteration 6 [185.1 s]: rank_loss = 0.642042 [23.66 s],
NDCG: [ 0.75920838  0.74440668  0.74000008  0.74032407  0.74505858  0.75267764
  0.76252675  0.77429088  0.7877954   0.80186597]
Iteration 7 [150.7 s]: rank_loss = 0.614310 [24.46 s],
NDCG: [ 0.76339028  0.74657408  0.74236633  0.74232271  0.74697976  0.75492366
  0.76463878  0.77632058  0.78945394  0.80342637]
Iteration 7 [178.8 s]: rank_loss = 0.641731 [23.85 s],
NDCG: [ 0.75846035  0.74522309  0.74043806  0.74053589  0.74489371  0.75291208
  0.76304241  0.77480839  0.78805575  0.80199461]
Iteration 8 [148.7 s]: rank_loss = 0.613351 [24.36 s],
NDCG: [ 0.76031975  0.74706627  0.74210042  0.74245654  0.74695697  0.75500146
  0.76496614  0.77632518  0.7895024   0.80353988]
Iteration 8 [183.0 s]: rank_loss = 0.641557 [23.45 s],
NDCG: [ 0.75732198  0.74299864  0.73871795  0.73979187  0.74462053  0.75279215
  0.76302701  0.77488215  0.78772296  0.80178872]
Iteration 9 [150.2 s]: rank_loss = 0.614032 [24.25 s],
NDCG: [ 0.75831414  0.74534966  0.74184429  0.74274124  0.74700716  0.75484545
  0.76452148  0.77625608  0.78937042  0.80340958]
Iteration 9 [178.9 s]: rank_loss = 0.642004 [24.58 s],
NDCG: [ 0.75535253  0.74278996  0.73945176  0.74045728  0.74507992  0.75281962
  0.76285993  0.77469004  0.78781894  0.8015903 ]
Iteration 10 [151.4 s]: rank_loss = 0.613639 [23.86 s],
NDCG: [ 0.76287871  0.74724878  0.74320133  0.7430787   0.74755403  0.75535844
  0.76558036  0.77697809  0.78985367  0.80374998]
Iteration 10 [172.8 s]: rank_loss = 0.641304 [21.62 s],
NDCG: [ 0.75978095  0.74535607  0.74182312  0.74134987  0.74582967  0.75349386
  0.7636204   0.77533633  0.78827277  0.80260177]
Iteration 11 [144.0 s]: rank_loss = 0.613481 [21.68 s],
NDCG: [ 0.76123536  0.74690722  0.7430113   0.74337141  0.74741392  0.75554151
  0.76520807  0.77686991  0.78972719  0.80378663]
Iteration 11 [171.1 s]: rank_loss = 0.641174 [21.86 s],
NDCG: [ 0.75834275  0.74621928  0.74202809  0.74194338  0.74624669  0.754052
  0.76398631  0.77554264  0.78897546  0.80307356]
Iteration 12 [145.3 s]: rank_loss = 0.613720 [21.67 s],
NDCG: [ 0.7602702   0.74613345  0.74272519  0.74294854  0.7473726   0.75489108
  0.76483375  0.77646867  0.78968352  0.80388849]
Iteration 12 [170.1 s]: rank_loss = 0.641422 [21.75 s],
NDCG: [ 0.75950928  0.74521054  0.74102693  0.74135613  0.74631335  0.75372338
  0.7635283   0.7753073   0.78848767  0.80272637]
Iteration 13 [145.1 s]: rank_loss = 0.613505 [21.78 s],
NDCG: [ 0.76028768  0.74689142  0.74297566  0.74278987  0.74776126  0.75531173
  0.76481907  0.77691951  0.78976128  0.80389336]
Iteration 13 [171.5 s]: rank_loss = 0.641558 [21.66 s],
NDCG: [ 0.7588762   0.74544706  0.74117747  0.74132242  0.74602036  0.75428102
  0.76448105  0.77590193  0.78879763  0.80278211]
Iteration 14 [231.9 s]: rank_loss = 0.613337 [28.21 s],
NDCG: [ 0.76230267  0.74781477  0.74328104  0.7435297   0.74788409  0.75560136
  0.76577471  0.77712012  0.78999197  0.80400263]
Iteration 14 [181.2 s]: rank_loss = 0.641254 [27.09 s],
NDCG: [ 0.75907461  0.74629082  0.74240353  0.74247955  0.74627746  0.75428457
  0.76439936  0.77605552  0.78886125  0.80317585]
Iteration 15 [154.2 s]: rank_loss = 0.613559 [26.67 s],
NDCG: [ 0.76390078  0.74866309  0.74331555  0.74402713  0.74841592  0.75586155
  0.76577125  0.77749516  0.79019186  0.80450736]
Iteration 15 [174.9 s]: rank_loss = 0.640526 [21.72 s],
NDCG: [ 0.75971982  0.74551171  0.74078545  0.74141689  0.7462698   0.75427487
  0.76397558  0.77553998  0.78847833  0.80267774]
Iteration 16 [144.2 s]: rank_loss = 0.613562 [21.88 s],
NDCG: [ 0.76235064  0.74826596  0.74315931  0.74349306  0.74872953  0.75584654
  0.76556929  0.77706403  0.78983617  0.80401153]
Iteration 16 [171.8 s]: rank_loss = 0.640775 [21.88 s],
NDCG: [ 0.76195541  0.74707342  0.74210927  0.74250938  0.74724276  0.7547566
  0.7646462   0.77607926  0.78893807  0.80317151]
Iteration 17 [145.1 s]: rank_loss = 0.613136 [21.70 s],
NDCG: [ 0.7619502   0.74778266  0.74396245  0.74426891  0.74814294  0.75556404
  0.76532542  0.77685641  0.78958272  0.80396577]
Iteration 17 [173.4 s]: rank_loss = 0.640805 [21.86 s],
NDCG: [ 0.75973365  0.74631043  0.7426418   0.74288776  0.74719954  0.75456387
  0.76417033  0.77583213  0.78892241  0.80307537]
Iteration 18 [144.1 s]: rank_loss = 0.613115 [21.72 s],
NDCG: [ 0.76047018  0.74644701  0.74261913  0.74291463  0.74741924  0.75515999
  0.76504119  0.77671613  0.78951245  0.80391168]
Iteration 18 [172.6 s]: rank_loss = 0.641170 [21.90 s],
NDCG: [ 0.75715156  0.74410537  0.73951823  0.73997056  0.74539231  0.75285833
  0.76263171  0.77439874  0.78745745  0.80201019]
Iteration 19 [146.2 s]: rank_loss = 0.612890 [21.95 s],
NDCG: [ 0.76037176  0.74734947  0.74372119  0.74312931  0.74800178  0.75517378
  0.76493724  0.77665172  0.78957409  0.80364596]
Iteration 19 [171.5 s]: rank_loss = 0.640843 [21.75 s],
NDCG: [ 0.75879697  0.74656222  0.74173798  0.74182788  0.74644701  0.75348862
  0.76370252  0.77531115  0.78862691  0.80269271]
End. Best Iteration 15.


liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000 --layers [128,64,32,16,8] --reg_layers [0,0,0,0,0]
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[128,64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0,0]', verbose=1) 
Load data done [349.6 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [35.4], Init: 
Init_NDCG: [ 0.56695827  0.57140389  0.57650971  0.58652927  0.59868476  0.6131709
  0.62972893  0.64767388  0.66829185  0.69013846]
RatingInit_NDCG: [ 0.55967645  0.56674892  0.57480717  0.58506686  0.59783637  0.61217912
  0.62888073  0.64747125  0.66782623  0.68934781]
Iteration 0 [172.5 s]: rank_loss = 0.628788 [32.42 s],
NDCG: [ 0.75734413  0.7453968   0.74090967  0.74055942  0.74499387  0.75286251
  0.76239729  0.77445733  0.78726829  0.80195794]
Iteration 0 [182.3 s]: rank_loss = 0.652082 [31.70 s],
NDCG: [ 0.7325253   0.72221025  0.71934743  0.72138018  0.72663826  0.73487403
  0.74524654  0.75780674  0.77187332  0.78735513]
Iteration 1 [177.8 s]: rank_loss = 0.618217 [32.92 s],
NDCG: [ 0.76031611  0.74534341  0.74125512  0.74131203  0.74594848  0.7539018
  0.76353594  0.77509894  0.78803453  0.80244645]
Iteration 1 [200.8 s]: rank_loss = 0.644039 [31.25 s],
NDCG: [ 0.75119735  0.73576866  0.73215275  0.73296809  0.73810131  0.74628397
  0.75638985  0.76861378  0.78247386  0.79663025]
Iteration 2 [176.7 s]: rank_loss = 0.616502 [34.11 s],
NDCG: [ 0.76155244  0.74611765  0.74118349  0.7418573   0.74611725  0.75349127
  0.76402764  0.77550384  0.78865856  0.8028502 ]
Iteration 2 [214.3 s]: rank_loss = 0.642954 [32.66 s],
NDCG: [ 0.75782174  0.74372017  0.73776194  0.73841919  0.74295882  0.75101924
  0.76083079  0.77226348  0.78537216  0.80015736]
Iteration 3 [182.3 s]: rank_loss = 0.615434 [36.02 s],
NDCG: [ 0.76015544  0.74619762  0.74230551  0.74287292  0.74677325  0.75419786
  0.76439126  0.77589361  0.78913212  0.80330987]
Iteration 3 [211.2 s]: rank_loss = 0.642702 [33.45 s],
NDCG: [ 0.75854493  0.74384684  0.73937371  0.73999456  0.74422388  0.75163386
  0.76141565  0.77325925  0.78653038  0.8012963 ]
Iteration 4 [609.4 s]: rank_loss = 0.615241 [31.38 s],
NDCG: [ 0.7612748   0.74728125  0.74248589  0.74318051  0.7472109   0.75507502
  0.76499762  0.77666697  0.78965446  0.80348335]
Iteration 4 [208.2 s]: rank_loss = 0.642524 [26.02 s],
NDCG: [ 0.75712088  0.74300212  0.73768313  0.73800194  0.74277464  0.75057368
  0.76104196  0.77291927  0.78558069  0.80039631]
Iteration 5 [173.2 s]: rank_loss = 0.614687 [35.54 s],
NDCG: [ 0.76285135  0.74673774  0.74246329  0.74201511  0.74666805  0.75455385
  0.76482533  0.77634338  0.78944223  0.80360152]
Iteration 5 [193.0 s]: rank_loss = 0.642697 [27.49 s],
NDCG: [ 0.75801229  0.74309379  0.73773527  0.7383839   0.74372783  0.75166053
  0.76188796  0.77360025  0.78705845  0.8012787 ]
Iteration 6 [159.3 s]: rank_loss = 0.614350 [28.68 s],
NDCG: [ 0.76319188  0.74760361  0.7433212   0.74393377  0.74842279  0.75582608
  0.76542518  0.77706813  0.79002256  0.80428402]
Iteration 6 [185.1 s]: rank_loss = 0.642042 [23.66 s],
NDCG: [ 0.75920838  0.74440668  0.74000008  0.74032407  0.74505858  0.75267764
  0.76252675  0.77429088  0.7877954   0.80186597]
Iteration 7 [150.7 s]: rank_loss = 0.614310 [24.46 s],
NDCG: [ 0.76339028  0.74657408  0.74236633  0.74232271  0.74697976  0.75492366
  0.76463878  0.77632058  0.78945394  0.80342637]
Iteration 7 [178.8 s]: rank_loss = 0.641731 [23.85 s],
NDCG: [ 0.75846035  0.74522309  0.74043806  0.74053589  0.74489371  0.75291208
  0.76304241  0.77480839  0.78805575  0.80199461]
Iteration 8 [148.7 s]: rank_loss = 0.613351 [24.36 s],
NDCG: [ 0.76031975  0.74706627  0.74210042  0.74245654  0.74695697  0.75500146
  0.76496614  0.77632518  0.7895024   0.80353988]
Iteration 8 [183.0 s]: rank_loss = 0.641557 [23.45 s],
NDCG: [ 0.75732198  0.74299864  0.73871795  0.73979187  0.74462053  0.75279215
  0.76302701  0.77488215  0.78772296  0.80178872]
Iteration 9 [150.2 s]: rank_loss = 0.614032 [24.25 s],
NDCG: [ 0.75831414  0.74534966  0.74184429  0.74274124  0.74700716  0.75484545
  0.76452148  0.77625608  0.78937042  0.80340958]
Iteration 9 [178.9 s]: rank_loss = 0.642004 [24.58 s],
NDCG: [ 0.75535253  0.74278996  0.73945176  0.74045728  0.74507992  0.75281962
  0.76285993  0.77469004  0.78781894  0.8015903 ]
Iteration 10 [151.4 s]: rank_loss = 0.613639 [23.86 s],
NDCG: [ 0.76287871  0.74724878  0.74320133  0.7430787   0.74755403  0.75535844
  0.76558036  0.77697809  0.78985367  0.80374998]
Iteration 10 [172.8 s]: rank_loss = 0.641304 [21.62 s],
NDCG: [ 0.75978095  0.74535607  0.74182312  0.74134987  0.74582967  0.75349386
  0.7636204   0.77533633  0.78827277  0.80260177]
Iteration 11 [144.0 s]: rank_loss = 0.613481 [21.68 s],
NDCG: [ 0.76123536  0.74690722  0.7430113   0.74337141  0.74741392  0.75554151
  0.76520807  0.77686991  0.78972719  0.80378663]
Iteration 11 [171.1 s]: rank_loss = 0.641174 [21.86 s],
NDCG: [ 0.75834275  0.74621928  0.74202809  0.74194338  0.74624669  0.754052
  0.76398631  0.77554264  0.78897546  0.80307356]
Iteration 12 [145.3 s]: rank_loss = 0.613720 [21.67 s],
NDCG: [ 0.7602702   0.74613345  0.74272519  0.74294854  0.7473726   0.75489108
  0.76483375  0.77646867  0.78968352  0.80388849]
Iteration 12 [170.1 s]: rank_loss = 0.641422 [21.75 s],
NDCG: [ 0.75950928  0.74521054  0.74102693  0.74135613  0.74631335  0.75372338
  0.7635283   0.7753073   0.78848767  0.80272637]
Iteration 13 [145.1 s]: rank_loss = 0.613505 [21.78 s],
NDCG: [ 0.76028768  0.74689142  0.74297566  0.74278987  0.74776126  0.75531173
  0.76481907  0.77691951  0.78976128  0.80389336]
Iteration 13 [171.5 s]: rank_loss = 0.641558 [21.66 s],
NDCG: [ 0.7588762   0.74544706  0.74117747  0.74132242  0.74602036  0.75428102
  0.76448105  0.77590193  0.78879763  0.80278211]
Iteration 14 [231.9 s]: rank_loss = 0.613337 [28.21 s],
NDCG: [ 0.76230267  0.74781477  0.74328104  0.7435297   0.74788409  0.75560136
  0.76577471  0.77712012  0.78999197  0.80400263]
Iteration 14 [181.2 s]: rank_loss = 0.641254 [27.09 s],
NDCG: [ 0.75907461  0.74629082  0.74240353  0.74247955  0.74627746  0.75428457
  0.76439936  0.77605552  0.78886125  0.80317585]
Iteration 15 [154.2 s]: rank_loss = 0.613559 [26.67 s],
NDCG: [ 0.76390078  0.74866309  0.74331555  0.74402713  0.74841592  0.75586155
  0.76577125  0.77749516  0.79019186  0.80450736]
Iteration 15 [174.9 s]: rank_loss = 0.640526 [21.72 s],
NDCG: [ 0.75971982  0.74551171  0.74078545  0.74141689  0.7462698   0.75427487
  0.76397558  0.77553998  0.78847833  0.80267774]
Iteration 16 [144.2 s]: rank_loss = 0.613562 [21.88 s],
NDCG: [ 0.76235064  0.74826596  0.74315931  0.74349306  0.74872953  0.75584654
  0.76556929  0.77706403  0.78983617  0.80401153]
Iteration 16 [171.8 s]: rank_loss = 0.640775 [21.88 s],
NDCG: [ 0.76195541  0.74707342  0.74210927  0.74250938  0.74724276  0.7547566
  0.7646462   0.77607926  0.78893807  0.80317151]
Iteration 17 [145.1 s]: rank_loss = 0.613136 [21.70 s],
NDCG: [ 0.7619502   0.74778266  0.74396245  0.74426891  0.74814294  0.75556404
  0.76532542  0.77685641  0.78958272  0.80396577]
Iteration 17 [173.4 s]: rank_loss = 0.640805 [21.86 s],
NDCG: [ 0.75973365  0.74631043  0.7426418   0.74288776  0.74719954  0.75456387
  0.76417033  0.77583213  0.78892241  0.80307537]
Iteration 18 [144.1 s]: rank_loss = 0.613115 [21.72 s],
NDCG: [ 0.76047018  0.74644701  0.74261913  0.74291463  0.74741924  0.75515999
  0.76504119  0.77671613  0.78951245  0.80391168]
Iteration 18 [172.6 s]: rank_loss = 0.641170 [21.90 s],
NDCG: [ 0.75715156  0.74410537  0.73951823  0.73997056  0.74539231  0.75285833
  0.76263171  0.77439874  0.78745745  0.80201019]
Iteration 19 [146.2 s]: rank_loss = 0.612890 [21.95 s],
NDCG: [ 0.76037176  0.74734947  0.74372119  0.74312931  0.74800178  0.75517378
  0.76493724  0.77665172  0.78957409  0.80364596]
Iteration 19 [171.5 s]: rank_loss = 0.640843 [21.75 s],
NDCG: [ 0.75879697  0.74656222  0.74173798  0.74182788  0.74644701  0.75348862
  0.76370252  0.77531115  0.78862691  0.80269271]
End. Best Iteration 15.

10. update for rank_u with rating initialization but MLP [128,32,8]
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000 --layers [128,32,8] --reg_layers [0,0,0]
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[128,32,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0]', verbose=1) 
Time: [26.6], Init: 
Init_NDCG: [ 0.56208488  0.56871684  0.57513885  0.58582199  0.5982239   0.61260029
  0.62896248  0.64726066  0.66717818  0.6894387 ]
RatingInit_NDCG: [ 0.56461101  0.56913985  0.5763427   0.58654868  0.59841236  0.61311483
  0.62945386  0.64764873  0.66746811  0.68958339]
Iteration 0 [150.8 s]: rank_loss = 0.631739 [23.63 s],
NDCG: [ 0.7549435   0.74114662  0.73653109  0.73712774  0.74161709  0.74934624
  0.75978996  0.77175613  0.78534189  0.79970184]
Iteration 1 [156.2 s]: rank_loss = 0.615730 [22.69 s],
NDCG: [ 0.7535633   0.74299992  0.73765824  0.73743298  0.74214809  0.75010807
  0.7606119   0.77240362  0.78587844  0.80027237]
Iteration 2 [154.5 s]: rank_loss = 0.615174 [22.74 s],
NDCG: [ 0.75632255  0.74379858  0.73916032  0.7394434   0.74379521  0.75192366
  0.76184198  0.7734649   0.78715988  0.80155681]
Iteration 3 [154.5 s]: rank_loss = 0.614567 [22.97 s],
NDCG: [ 0.75641894  0.74214726  0.73783085  0.73906879  0.74382469  0.75152384
  0.76174133  0.77360576  0.78701595  0.80133581]
Iteration 4 [157.0 s]: rank_loss = 0.614422 [22.83 s],
NDCG: [ 0.75931088  0.7458596   0.74091842  0.74095921  0.74509651  0.75258457
  0.76330203  0.77475705  0.787762    0.80207909]
Iteration 5 [155.6 s]: rank_loss = 0.614124 [22.79 s],
NDCG: [ 0.75962059  0.74359977  0.73996221  0.74035749  0.74453994  0.75245813
  0.7621412   0.77407873  0.7874437   0.80149723]
Iteration 6 [153.4 s]: rank_loss = 0.614008 [22.92 s],
NDCG: [ 0.75981931  0.74471494  0.74022232  0.74042929  0.74547464  0.7530677
  0.76320727  0.77473378  0.78758295  0.80195468]
Iteration 7 [156.9 s]: rank_loss = 0.613601 [23.96 s],
NDCG: [ 0.7598605   0.74531083  0.74087981  0.74087966  0.7455834   0.75354154
  0.76314008  0.77531003  0.78847337  0.80264218]
Iteration 8 [153.6 s]: rank_loss = 0.613199 [22.67 s],
NDCG: [ 0.75988723  0.74596594  0.74187334  0.74167919  0.74583607  0.7538132
  0.7635436   0.77561311  0.78872989  0.80283288]
Iteration 9 [153.8 s]: rank_loss = 0.613876 [23.91 s],
NDCG: [ 0.75868485  0.74548015  0.74090638  0.74066992  0.7457103   0.75350736
  0.76325014  0.77514377  0.78844361  0.80253768]
Iteration 10 [160.2 s]: rank_loss = 0.613433 [23.34 s],
NDCG: [ 0.75923196  0.74524204  0.74002999  0.74026848  0.74519079  0.75308249
  0.76339716  0.77498161  0.78820199  0.80227881]
Iteration 11 [154.0 s]: rank_loss = 0.613222 [23.11 s],
NDCG: [ 0.76096383  0.745774    0.74036346  0.74080612  0.74565942  0.75354644
  0.7637098   0.77515161  0.78854935  0.80242638]
Iteration 12 [155.0 s]: rank_loss = 0.612971 [23.78 s],
NDCG: [ 0.75955802  0.74497283  0.74108872  0.74155547  0.7460809   0.7540097
  0.76403463  0.77593715  0.78919695  0.80302007]
Iteration 13 [157.4 s]: rank_loss = 0.613356 [22.94 s],
NDCG: [ 0.76025763  0.74562781  0.7414866   0.74166947  0.74662021  0.75447723
  0.76389086  0.77578845  0.78903741  0.80296823]
Iteration 14 [156.7 s]: rank_loss = 0.613493 [23.81 s],
NDCG: [ 0.76091793  0.74646051  0.74203518  0.74218487  0.74638177  0.75424502
  0.76408526  0.77582473  0.78890657  0.80288873]
Iteration 15 [161.2 s]: rank_loss = 0.613185 [23.93 s],
NDCG: [ 0.75934201  0.74622496  0.74140544  0.74205348  0.7464364   0.75406469
  0.76402608  0.77581834  0.78872174  0.80281752]
Iteration 16 [163.9 s]: rank_loss = 0.613014 [22.63 s],
NDCG: [ 0.75945363  0.74625103  0.74107755  0.74174517  0.7462869   0.7536847
  0.76383539  0.77556904  0.78861897  0.80235163]
Iteration 17 [155.3 s]: rank_loss = 0.612756 [23.00 s],
NDCG: [ 0.75824496  0.74480196  0.74063974  0.74127153  0.74584834  0.75394389
  0.76364248  0.77541219  0.78894007  0.8027542 ]
Iteration 18 [156.7 s]: rank_loss = 0.612821 [23.06 s],
NDCG: [ 0.76264509  0.74701457  0.74210326  0.74200558  0.7469339   0.7547044
  0.76438027  0.77609783  0.78920092  0.80329866]
Iteration 19 [155.3 s]: rank_loss = 0.612856 [20.60 s],
NDCG: [ 0.76088302  0.74631505  0.74217483  0.74220274  0.74676339  0.75448446
  0.76399075  0.7757737   0.78920494  0.80301834]
End. Best Iteration 18.

