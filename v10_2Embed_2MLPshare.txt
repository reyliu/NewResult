1. alternate update for rating, rank_u, rank_i
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [344.4 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [30.7], Init: 
Init_NDCG: [ 0.56655988  0.57013436  0.57655407  0.58627099  0.59744336  0.61154802
  0.62843613  0.64673022  0.66705792  0.68937433]
Iteration 0 [3.9 s]: rating_loss = 15.422400 [29.47 s],
NDCG: [ 0.56593008  0.56772002  0.57455616  0.58502495  0.59816603  0.61295267
  0.6295212   0.64809277  0.66797774  0.68984434]
Iteration 0 [79.1 s]: rank_loss = 0.632511 [28.66 s],
NDCG: [ 0.76020229  0.74490501  0.74100361  0.74091924  0.74536974  0.75288114
  0.76292169  0.77462582  0.78761265  0.80201747]
Iteration 0 [80.4 s]: rank_loss = 0.652605 [29.53 s],
NDCG: [ 0.74010335  0.73041338  0.72683222  0.7277475   0.7322272   0.74050813
  0.75120816  0.76334399  0.77759108  0.79221405]
Iteration 1 [0.5 s]: rating_loss = 9.425060 [28.72 s],
NDCG: [ 0.72629475  0.71956335  0.71772972  0.72011327  0.72488375  0.7336939
  0.74541444  0.75776501  0.77209831  0.78719733]
Iteration 1 [77.5 s]: rank_loss = 0.618545 [29.80 s],
NDCG: [ 0.75685411  0.74403458  0.73984132  0.74048181  0.74505893  0.75255305
  0.76271327  0.7744854   0.78752854  0.80189554]
Iteration 1 [88.9 s]: rank_loss = 0.644791 [27.45 s],
NDCG: [ 0.75461142  0.74200185  0.73795264  0.73897692  0.74362728  0.75142831
  0.76173454  0.77330929  0.78661903  0.80054446]
Iteration 2 [0.5 s]: rating_loss = 4.152434 [27.04 s],
NDCG: [ 0.75073483  0.73904579  0.73542453  0.73658131  0.74122015  0.74908492
  0.75899123  0.77123928  0.78456023  0.79877067]
Iteration 2 [77.5 s]: rank_loss = 0.615599 [28.75 s],
NDCG: [ 0.76028592  0.74677131  0.7424636   0.74186691  0.74626217  0.75384571
  0.76408022  0.77539073  0.78830629  0.80251477]
Iteration 2 [86.2 s]: rank_loss = 0.642573 [26.43 s],
NDCG: [ 0.75735073  0.7437749   0.73817985  0.73799103  0.74283779  0.75016404
  0.76048091  0.7721963   0.78585878  0.80009829]
Iteration 3 [0.5 s]: rating_loss = 2.285630 [27.25 s],
NDCG: [ 0.75618451  0.7429551   0.73759394  0.73766769  0.74238558  0.74963915
  0.75998857  0.771627    0.78536357  0.79964051]
Iteration 3 [74.9 s]: rank_loss = 0.615200 [27.17 s],
NDCG: [ 0.76108017  0.74584821  0.7420575   0.74196873  0.74651009  0.75385957
  0.7640283   0.77568394  0.78867526  0.8026276 ]
Iteration 3 [87.7 s]: rank_loss = 0.642527 [26.57 s],
NDCG: [ 0.75584542  0.74219437  0.73702139  0.7380443   0.74291423  0.75062101
  0.76110245  0.77260219  0.78550647  0.79986157]
Iteration 4 [0.5 s]: rating_loss = 1.515901 [25.61 s],
NDCG: [ 0.7559822   0.74220695  0.73692749  0.73804473  0.74304345  0.75069838
  0.76113299  0.77267715  0.78550749  0.79990141]
Iteration 4 [73.7 s]: rank_loss = 0.614445 [25.39 s],
NDCG: [ 0.76229185  0.74720817  0.74298559  0.74285138  0.74725165  0.7545832
  0.7644053   0.7758972   0.78920829  0.80327796]
Iteration 4 [88.0 s]: rank_loss = 0.642307 [27.45 s],
NDCG: [ 0.75528888  0.74276133  0.73804638  0.73821332  0.74326017  0.75121427
  0.76144927  0.77292454  0.78574471  0.80054804]
Iteration 5 [0.5 s]: rating_loss = 1.225531 [27.16 s],
NDCG: [ 0.75535491  0.74287339  0.73795804  0.73846495  0.74345066  0.75146912
  0.76162543  0.77296277  0.78588981  0.80059285]
Iteration 5 [75.9 s]: rank_loss = 0.614819 [28.37 s],
NDCG: [ 0.76305667  0.74789883  0.74375443  0.74331704  0.74706909  0.75461738
  0.76487448  0.77657378  0.7898064   0.80378787]
Iteration 5 [88.3 s]: rank_loss = 0.642535 [26.84 s],
NDCG: [ 0.75936168  0.74466408  0.73966961  0.74006759  0.74472128  0.75265549
  0.7625901   0.77440761  0.78778624  0.80177162]
Iteration 6 [0.4 s]: rating_loss = 1.119303 [27.95 s],
NDCG: [ 0.75960819  0.74496068  0.7398027   0.74021299  0.74500372  0.75285663
  0.76279701  0.7745901   0.7878955   0.80186652]
Iteration 6 [75.0 s]: rank_loss = 0.614246 [28.41 s],
NDCG: [ 0.76184078  0.74640119  0.74238699  0.74253429  0.74716939  0.75458139
  0.76462357  0.77592914  0.78931113  0.80334482]
Iteration 6 [89.5 s]: rank_loss = 0.641913 [28.34 s],
NDCG: [ 0.75770729  0.74525343  0.74017409  0.74086279  0.74542718  0.75273278
  0.76258851  0.77468855  0.78805401  0.8022845 ]
Iteration 7 [0.5 s]: rating_loss = 1.047050 [27.11 s],
NDCG: [ 0.75778747  0.74518855  0.74023944  0.74109164  0.74542594  0.75278214
  0.76265245  0.77474337  0.7881576   0.80227204]
Iteration 7 [75.1 s]: rank_loss = 0.614012 [27.78 s],
NDCG: [ 0.7648093   0.74770324  0.74281389  0.74389314  0.74817702  0.75536738
  0.76527142  0.77723417  0.79000437  0.80414523]
Iteration 7 [87.4 s]: rank_loss = 0.641951 [26.30 s],
NDCG: [ 0.75895306  0.74431354  0.74002708  0.74036845  0.74579493  0.75345379
  0.76317971  0.77485965  0.78819028  0.8023682 ]
Iteration 8 [0.4 s]: rating_loss = 1.016861 [25.93 s],
NDCG: [ 0.75889646  0.74434016  0.74005151  0.74049224  0.74588534  0.75354096
  0.76322532  0.77491115  0.78821038  0.80235274]
Iteration 8 [73.7 s]: rank_loss = 0.613968 [27.65 s],
NDCG: [ 0.76419055  0.74830338  0.74315571  0.74292318  0.74778055  0.75550362
  0.7655885   0.77706768  0.78990687  0.80376441]
Iteration 8 [88.1 s]: rank_loss = 0.641586 [24.77 s],
NDCG: [ 0.76009695  0.74492613  0.73958538  0.73986656  0.7443107   0.75214087
  0.76205507  0.77404428  0.78718129  0.80152524]
Iteration 9 [0.4 s]: rating_loss = 0.999707 [27.93 s],
NDCG: [ 0.75997778  0.74502746  0.73972549  0.7399479   0.7444694   0.75215164
  0.76203467  0.77397642  0.78712946  0.80154836]
Iteration 9 [74.6 s]: rank_loss = 0.613861 [28.24 s],
NDCG: [ 0.76331325  0.74822888  0.74353557  0.7434809   0.74785185  0.75515534
  0.76480973  0.77688308  0.78985733  0.80385382]
Iteration 9 [85.9 s]: rank_loss = 0.641723 [26.42 s],
NDCG: [ 0.76009475  0.74523621  0.74103482  0.7413869   0.74579909  0.75332949
  0.76342935  0.77522893  0.78845704  0.80267131]
Iteration 10 [0.4 s]: rating_loss = 0.965783 [25.27 s],
NDCG: [ 0.76000262  0.74524997  0.7409579   0.74134262  0.74571986  0.75338339
  0.76341647  0.77523264  0.78842789  0.80269839]
Iteration 10 [74.2 s]: rank_loss = 0.613701 [25.19 s],
NDCG: [ 0.76159867  0.74696336  0.74241313  0.74256637  0.7474388   0.75482915
  0.76558683  0.77717679  0.78969851  0.80364208]
Iteration 10 [87.5 s]: rank_loss = 0.641574 [28.01 s],
NDCG: [ 0.75984289  0.74588901  0.74071127  0.74113991  0.74587376  0.75410606
  0.7639087   0.77563853  0.78869367  0.80292017]
Iteration 11 [0.5 s]: rating_loss = 0.955966 [25.17 s],
NDCG: [ 0.75994791  0.74634882  0.74080696  0.7411902   0.74604165  0.75424236
  0.763918    0.77578592  0.78871337  0.80293583]
Iteration 11 [74.7 s]: rank_loss = 0.613601 [27.50 s],
NDCG: [ 0.76293876  0.7479575   0.74371458  0.74400684  0.74789572  0.75570068
  0.76582421  0.77724894  0.7901622   0.8040909 ]
Iteration 11 [89.3 s]: rank_loss = 0.641589 [28.27 s],
NDCG: [ 0.76043528  0.74507511  0.74049003  0.74135625  0.74576898  0.75381718
  0.7637238   0.7755609   0.78849372  0.80257872]
Iteration 12 [0.5 s]: rating_loss = 0.942808 [28.10 s],
NDCG: [ 0.7603834   0.74524007  0.74060124  0.74128854  0.74581302  0.75385563
  0.76376564  0.77559028  0.78847961  0.80263993]
Iteration 12 [75.8 s]: rank_loss = 0.613573 [28.24 s],
NDCG: [ 0.76033403  0.74552576  0.7422311   0.7424923   0.74684683  0.75493039
  0.76486387  0.77638561  0.78968195  0.80385969]
Iteration 12 [89.2 s]: rank_loss = 0.641121 [28.15 s],
NDCG: [ 0.75706931  0.7443933   0.74073533  0.74112878  0.74594524  0.75375255
  0.76394717  0.77538708  0.78875168  0.80292322]
Iteration 13 [0.4 s]: rating_loss = 0.912827 [25.55 s],
NDCG: [ 0.75694323  0.74461611  0.74072236  0.74121805  0.74603993  0.75382983
  0.76397593  0.77549336  0.78874849  0.80295654]
Iteration 13 [71.6 s]: rank_loss = 0.613387 [26.12 s],
NDCG: [ 0.76073367  0.74648021  0.7426556   0.74272801  0.74775622  0.75526918
  0.76513927  0.77670006  0.78978087  0.80391244]
Iteration 13 [85.7 s]: rank_loss = 0.640881 [27.14 s],
NDCG: [ 0.7601438   0.74533999  0.74168634  0.74210332  0.74680931  0.75445466
  0.76439444  0.7763242   0.78934093  0.80316715]
Iteration 14 [0.5 s]: rating_loss = 0.908439 [26.68 s],
NDCG: [ 0.75989383  0.74514935  0.74174178  0.74197139  0.74675389  0.75436715
  0.76429354  0.77633074  0.78922848  0.80313275]
Iteration 14 [74.9 s]: rank_loss = 0.613443 [27.79 s],
NDCG: [ 0.76164048  0.74783733  0.74291013  0.74339146  0.74805943  0.7552977
  0.76558708  0.77735463  0.79021782  0.80395659]
Iteration 14 [85.9 s]: rank_loss = 0.641358 [26.28 s],
NDCG: [ 0.75885747  0.74600896  0.74168148  0.74254809  0.74693417  0.75446063
  0.76471037  0.77641348  0.78923942  0.80313431]
Iteration 15 [0.4 s]: rating_loss = 0.894171 [27.58 s],
NDCG: [ 0.75929359  0.74643795  0.74185578  0.74279075  0.74708633  0.75454591
  0.76489136  0.77654387  0.78938077  0.80325599]
Iteration 15 [74.4 s]: rank_loss = 0.613384 [27.82 s],
NDCG: [ 0.7626127   0.74732942  0.74403229  0.74420617  0.7480088   0.75581722
  0.76555959  0.77738819  0.79017374  0.8039578 ]
Iteration 15 [87.1 s]: rank_loss = 0.641047 [27.47 s],
NDCG: [ 0.76325791  0.74672702  0.74281723  0.7429665   0.74738857  0.75489655
  0.76485025  0.77652666  0.78948918  0.80355082]
Iteration 16 [0.4 s]: rating_loss = 0.879612 [25.97 s],
NDCG: [ 0.76284538  0.74646673  0.74267987  0.74293546  0.74737044  0.75495082
  0.76488991  0.77644294  0.78944915  0.80345887]
Iteration 16 [75.1 s]: rank_loss = 0.613214 [27.12 s],
NDCG: [ 0.76251397  0.74814112  0.74359669  0.74407836  0.74799551  0.75570234
  0.76539896  0.77729789  0.7904484   0.80415092]
Iteration 16 [87.0 s]: rank_loss = 0.641111 [26.47 s],
NDCG: [ 0.75973913  0.7468177   0.74210475  0.74321509  0.74696373  0.75454417
  0.7640869   0.77608643  0.78904509  0.80318474]
Iteration 17 [0.5 s]: rating_loss = 0.874393 [26.50 s],
NDCG: [ 0.75983723  0.74700682  0.74237061  0.74319383  0.7469914   0.75468707
  0.76409495  0.77605946  0.78904106  0.8032078 ]
Iteration 17 [74.2 s]: rank_loss = 0.612889 [25.85 s],
NDCG: [ 0.76324928  0.7475741   0.74268928  0.74340512  0.7479993   0.75522982
  0.76521797  0.77692326  0.78986729  0.80385349]
Iteration 17 [88.0 s]: rank_loss = 0.640790 [28.18 s],
NDCG: [ 0.76209106  0.74632651  0.74153082  0.74153765  0.74646522  0.75375409
  0.76372646  0.77598608  0.78913018  0.80294483]
Iteration 18 [0.5 s]: rating_loss = 0.868386 [28.17 s],
NDCG: [ 0.76203509  0.74650892  0.74161263  0.74171979  0.74657158  0.7537801
  0.76381459  0.77598268  0.78915846  0.80305187]
Iteration 18 [76.2 s]: rank_loss = 0.613264 [28.14 s],
NDCG: [ 0.76275608  0.74631986  0.74266286  0.74301104  0.74722603  0.7553312
  0.76527726  0.7770019   0.78965612  0.80397415]
Iteration 18 [89.6 s]: rank_loss = 0.641111 [28.21 s],
NDCG: [ 0.760196    0.745107    0.74128926  0.74153004  0.74610029  0.75407892
  0.76382543  0.77568662  0.78866272  0.80280398]
Iteration 19 [0.5 s]: rating_loss = 0.876862 [28.13 s],
NDCG: [ 0.76009507  0.74498639  0.74115114  0.74164797  0.74602365  0.7540472
  0.76385651  0.77568645  0.78871434  0.80284464]
Iteration 19 [76.4 s]: rank_loss = 0.612778 [28.18 s],
NDCG: [ 0.7604881   0.74570571  0.74209863  0.74284607  0.7472654   0.75475288
  0.76507614  0.77674251  0.78935713  0.80350946]
Iteration 19 [89.7 s]: rank_loss = 0.640838 [28.16 s],
NDCG: [ 0.75980296  0.74518435  0.74103186  0.74153188  0.74602388  0.75366139
  0.76417885  0.77593569  0.78882362  0.8029615 ]
End. Best Iteration 16.

2. Alternate update for rank_u and rank_i with rating initialization
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [346.6 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [30.7], Init: 
Init_NDCG: [ 0.5600455   0.56366983  0.57205238  0.58267429  0.5958236   0.61053602
  0.62691519  0.64559816  0.66600881  0.68788993]
RatingInit_NDCG: [ 0.56241566  0.56581262  0.57392443  0.58497462  0.5974234   0.61224682
  0.62878644  0.64653954  0.66636272  0.68834213]
Iteration 0 [77.6 s]: rank_loss = 0.632860 [28.20 s],
NDCG: [ 0.75727464  0.74418635  0.73973663  0.74020163  0.74484898  0.75243137
  0.76264188  0.77432156  0.78721083  0.80125797]
Iteration 0 [80.5 s]: rank_loss = 0.657931 [26.37 s],
NDCG: [ 0.67996443  0.67231676  0.67153105  0.67548293  0.68284921  0.69318476
  0.70598374  0.72077567  0.7371872   0.75468104]
Iteration 1 [75.3 s]: rank_loss = 0.620111 [29.34 s],
NDCG: [ 0.75999777  0.7455856   0.74150827  0.74148518  0.74596267  0.7541733
  0.76440197  0.7759421   0.78893317  0.80288228]
Iteration 1 [85.2 s]: rank_loss = 0.645215 [27.64 s],
NDCG: [ 0.64732728  0.63902867  0.63777577  0.64110004  0.64914266  0.66017121
  0.67355571  0.68896622  0.70687015  0.72617162]
Iteration 2 [75.9 s]: rank_loss = 0.617278 [27.06 s],
NDCG: [ 0.76196372  0.74615052  0.74151386  0.74187821  0.74611387  0.75361329
  0.76363822  0.77547339  0.78857053  0.80254072]
Iteration 2 [88.0 s]: rank_loss = 0.643000 [28.60 s],
NDCG: [ 0.73795571  0.72342619  0.71683319  0.71676578  0.72120367  0.72916146
  0.73963819  0.7526196   0.767207    0.78282555]
Iteration 3 [75.2 s]: rank_loss = 0.615719 [28.69 s],
NDCG: [ 0.76070933  0.74605651  0.74145441  0.74238452  0.74634869  0.75429548
  0.76464452  0.77597644  0.78880232  0.80302207]
Iteration 3 [88.6 s]: rank_loss = 0.642820 [28.82 s],
NDCG: [ 0.75079632  0.73686254  0.73260353  0.73328598  0.73764974  0.74503049
  0.75521279  0.76738918  0.78099672  0.79554282]
Iteration 4 [76.1 s]: rank_loss = 0.614907 [28.57 s],
NDCG: [ 0.76286581  0.74776914  0.74332623  0.74343814  0.74762226  0.75490918
  0.76495744  0.77654334  0.78929371  0.80342742]
Iteration 4 [89.2 s]: rank_loss = 0.642441 [28.69 s],
NDCG: [ 0.76013846  0.74483076  0.73970805  0.73930525  0.74401668  0.7512355
  0.76096181  0.77258843  0.78609181  0.80026985]
Iteration 5 [76.1 s]: rank_loss = 0.615121 [29.24 s],
NDCG: [ 0.76155119  0.74572184  0.74137318  0.74214865  0.74681187  0.75434725
  0.76422819  0.77581871  0.78870832  0.80262485]
Iteration 5 [90.7 s]: rank_loss = 0.642235 [28.69 s],
NDCG: [ 0.7601438   0.7427353   0.73850434  0.7395541   0.74498837  0.75207994
  0.76173123  0.7731817   0.78629591  0.80050767]
Iteration 6 [76.2 s]: rank_loss = 0.614613 [28.78 s],
NDCG: [ 0.76419994  0.74581201  0.74181359  0.742468    0.74637748  0.75472634
  0.76432496  0.7760181   0.78890501  0.80301441]
Iteration 6 [89.8 s]: rank_loss = 0.642117 [28.76 s],
NDCG: [ 0.76275419  0.74371772  0.73945538  0.74027563  0.74464483  0.75256198
  0.76212099  0.7740746   0.78754195  0.8018099 ]
Iteration 7 [75.8 s]: rank_loss = 0.614333 [28.89 s],
NDCG: [ 0.76143453  0.74649827  0.7426672   0.74267082  0.74671518  0.75444364
  0.76433326  0.77600624  0.78913148  0.80329706]
Iteration 7 [89.7 s]: rank_loss = 0.641541 [28.82 s],
NDCG: [ 0.75949262  0.74554895  0.7417884   0.74095467  0.7455192   0.75343052
  0.7635289   0.77492881  0.788001    0.80237208]
Iteration 8 [76.4 s]: rank_loss = 0.614086 [28.62 s],
NDCG: [ 0.76452726  0.74790832  0.74291179  0.74324619  0.74790983  0.75544544
  0.76529156  0.77659179  0.78957693  0.80393092]
Iteration 8 [89.4 s]: rank_loss = 0.641859 [28.66 s],
NDCG: [ 0.76059469  0.74595049  0.7407096   0.74111471  0.74611695  0.75398056
  0.76376747  0.77534337  0.7886759   0.80269721]
Iteration 9 [76.6 s]: rank_loss = 0.613650 [30.71 s],
NDCG: [ 0.76385155  0.74715764  0.74232251  0.74261771  0.74661437  0.75443217
  0.76451387  0.77622346  0.78929921  0.80334376]
Iteration 9 [93.6 s]: rank_loss = 0.641797 [30.90 s],
NDCG: [ 0.76288122  0.74727304  0.74177536  0.74225808  0.74627029  0.75422039
  0.76420742  0.77571825  0.78879732  0.802877  ]
Iteration 10 [79.9 s]: rank_loss = 0.614057 [31.35 s],
NDCG: [ 0.76299567  0.74879738  0.74339049  0.74281247  0.74752911  0.75468826
  0.76454605  0.77619803  0.78955987  0.8038603 ]
Iteration 10 [93.9 s]: rank_loss = 0.641385 [31.05 s],
NDCG: [ 0.76177946  0.74660777  0.74179326  0.74135285  0.74632489  0.75341728
  0.76297951  0.7752817   0.78819492  0.80261519]
Iteration 11 [79.5 s]: rank_loss = 0.613747 [30.36 s],
NDCG: [ 0.76155842  0.74660871  0.74283197  0.74236234  0.74689022  0.75426185
  0.76446885  0.775997    0.78920891  0.80334127]
Iteration 11 [92.8 s]: rank_loss = 0.641495 [30.12 s],
NDCG: [ 0.76079215  0.74539948  0.74087545  0.74137009  0.74575029  0.75313326
  0.76302657  0.77478203  0.78787341  0.80200144]
Iteration 12 [78.6 s]: rank_loss = 0.613430 [29.53 s],
NDCG: [ 0.76186184  0.74717692  0.74279068  0.74301107  0.74739668  0.75484395
  0.76512844  0.77688481  0.78973874  0.80384822]
Iteration 12 [92.4 s]: rank_loss = 0.641360 [30.13 s],
NDCG: [ 0.75952155  0.74581145  0.74173386  0.74163495  0.74608155  0.75409266
  0.76394668  0.77531881  0.78851397  0.80271059]
Iteration 13 [78.7 s]: rank_loss = 0.613283 [30.53 s],
NDCG: [ 0.75974794  0.74625454  0.74200397  0.74249148  0.74681569  0.75483847
  0.76482885  0.77609251  0.78912617  0.80346038]
Iteration 13 [91.6 s]: rank_loss = 0.641232 [26.34 s],
NDCG: [ 0.75971838  0.74485056  0.74037853  0.74143229  0.74601943  0.75415669
  0.76386824  0.7753889   0.7885478   0.80276884]
Iteration 14 [75.8 s]: rank_loss = 0.612963 [28.62 s],
NDCG: [ 0.76049313  0.74704074  0.74240312  0.74262629  0.74698579  0.75486722
  0.76466704  0.77637264  0.78918194  0.80329176]
Iteration 14 [87.4 s]: rank_loss = 0.641038 [30.29 s],
NDCG: [ 0.75894349  0.74616106  0.74068169  0.74186344  0.74624715  0.75393459
  0.76386719  0.77511949  0.78788507  0.80206845]
Iteration 15 [77.7 s]: rank_loss = 0.612924 [29.93 s],
NDCG: [ 0.76229041  0.74804816  0.74305346  0.74298487  0.74729654  0.75509661
  0.76502776  0.77647892  0.78934567  0.8036224 ]
Iteration 15 [90.1 s]: rank_loss = 0.640756 [28.84 s],
NDCG: [ 0.75946401  0.74602759  0.74146143  0.74142568  0.74588584  0.75381749
  0.76382712  0.77519248  0.78847331  0.8027536 ]
Iteration 16 [76.9 s]: rank_loss = 0.613576 [30.21 s],
NDCG: [ 0.76175179  0.74672207  0.74176998  0.74231571  0.74662522  0.75449409
  0.76451451  0.77617437  0.78915033  0.80327265]
Iteration 16 [86.6 s]: rank_loss = 0.641148 [27.96 s],
NDCG: [ 0.76043654  0.74596812  0.74132732  0.74120327  0.74532858  0.75341119
  0.76363585  0.77520395  0.78851991  0.80252419]
Iteration 17 [76.7 s]: rank_loss = 0.612836 [30.31 s],
NDCG: [ 0.76205899  0.7464442   0.74167579  0.74163448  0.74661457  0.75421943
  0.7643611   0.77593397  0.78895988  0.80310119]
Iteration 17 [91.4 s]: rank_loss = 0.641145 [30.05 s],
NDCG: [ 0.76158923  0.7454612   0.74037281  0.74137816  0.7454065   0.75304964
  0.76328094  0.77497016  0.78784132  0.80205789]
Iteration 18 [77.9 s]: rank_loss = 0.612818 [29.01 s],
NDCG: [ 0.76347172  0.74714055  0.74187416  0.74168694  0.74650309  0.75490685
  0.76481352  0.77593101  0.78897067  0.80317301]
Iteration 18 [90.9 s]: rank_loss = 0.641218 [30.80 s],
NDCG: [ 0.76178795  0.74524419  0.74153895  0.74092088  0.74570169  0.7536442
  0.76398137  0.77542427  0.78818169  0.80234581]
Iteration 19 [77.5 s]: rank_loss = 0.613055 [25.84 s],
NDCG: [ 0.76194391  0.74694108  0.74284091  0.74254121  0.74690759  0.75463739
  0.76475596  0.77617781  0.78908736  0.80333012]
Iteration 19 [91.0 s]: rank_loss = 0.640913 [30.12 s],
NDCG: [ 0.7603856   0.74542795  0.7415675   0.74130027  0.74572949  0.75381276
  0.76419102  0.7752891   0.78815519  0.80234717]
End. Best Iteration 8.

liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [343.8 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [26.9], Init: 
Init_NDCG: [ 0.56012846  0.56682799  0.57637425  0.58630708  0.59913351  0.61370819
  0.63016994  0.64863016  0.6689168   0.6909162 ]
RatingInit_NDCG: [ 0.56685199  0.57301976  0.58048705  0.5904182   0.60180078  0.6161775
  0.63244417  0.65121633  0.67103214  0.69281741]
Iteration 0 [77.6 s]: rank_loss = 0.632103 [28.31 s],
NDCG: [ 0.75451961  0.74348315  0.73940586  0.73998675  0.74359976  0.75131361
  0.7619798   0.77355999  0.78659905  0.80107307]
Iteration 0 [81.4 s]: rank_loss = 0.651616 [28.53 s],
NDCG: [ 0.74157708  0.7300109   0.72701912  0.72875198  0.73393944  0.7421804
  0.75237775  0.76475393  0.77837512  0.79345189]
Iteration 1 [76.6 s]: rank_loss = 0.617331 [27.82 s],
NDCG: [ 0.76006299  0.74390109  0.73911542  0.74001059  0.74508228  0.75322477
  0.76304927  0.77469029  0.78772597  0.80191411]
Iteration 1 [88.1 s]: rank_loss = 0.644267 [28.45 s],
NDCG: [ 0.75588082  0.73981119  0.73548049  0.73617685  0.74184755  0.74995894
  0.76005854  0.77198308  0.78511392  0.79961419]
Iteration 2 [76.9 s]: rank_loss = 0.615582 [28.07 s],
NDCG: [ 0.76152006  0.74623924  0.74114229  0.74106624  0.7458661   0.75334603
  0.7639504   0.77573242  0.78881744  0.80282859]
Iteration 2 [89.0 s]: rank_loss = 0.643153 [28.08 s],
NDCG: [ 0.75743805  0.74436771  0.7383151   0.73836961  0.7436451   0.75173146
  0.76164163  0.77359352  0.78668232  0.80102529]
Iteration 3 [76.7 s]: rank_loss = 0.614525 [27.87 s],
NDCG: [ 0.75977466  0.74645818  0.74184258  0.7415802   0.74648792  0.75402678
  0.76395811  0.77580552  0.78874197  0.80285496]
Iteration 3 [89.1 s]: rank_loss = 0.642962 [27.84 s],
NDCG: [ 0.75500383  0.74104862  0.73646499  0.73795345  0.74300389  0.75106958
  0.76097969  0.77294644  0.78603968  0.80062716]
Iteration 4 [76.4 s]: rank_loss = 0.614734 [26.71 s],
NDCG: [ 0.75925823  0.74713727  0.74148307  0.74227216  0.74640514  0.75404302
  0.76436469  0.77608299  0.78893539  0.80286778]
Iteration 4 [90.2 s]: rank_loss = 0.642432 [28.12 s],
NDCG: [ 0.7575251   0.74424512  0.73898764  0.73990066  0.7448582   0.75245869
  0.76211443  0.7742611   0.78722779  0.8012998 ]
Iteration 5 [77.1 s]: rank_loss = 0.614507 [28.32 s],
NDCG: [ 0.75994634  0.74702004  0.74221361  0.74161253  0.74617525  0.75406064
  0.76421935  0.77606586  0.78890293  0.80319006]
Iteration 5 [92.9 s]: rank_loss = 0.642068 [29.84 s],
NDCG: [ 0.75604603  0.7440796   0.73926317  0.73949946  0.74389635  0.75166256
  0.76194467  0.77367776  0.78703051  0.80157748]
Iteration 6 [79.4 s]: rank_loss = 0.614116 [28.48 s],
NDCG: [ 0.76026957  0.7455871   0.74157299  0.74096199  0.74615426  0.75447989
  0.76435734  0.77616342  0.78875395  0.80311763]
Iteration 6 [93.3 s]: rank_loss = 0.642216 [29.50 s],
NDCG: [ 0.75738532  0.74343563  0.73846805  0.73904142  0.74397999  0.75194769
  0.76252705  0.77421867  0.78724609  0.80119349]
Iteration 7 [78.9 s]: rank_loss = 0.613928 [29.68 s],
NDCG: [ 0.76185304  0.74729386  0.74194938  0.74262754  0.7468725   0.75430724
  0.76450066  0.77640462  0.78934769  0.80343466]
Iteration 7 [92.9 s]: rank_loss = 0.642184 [29.43 s],
NDCG: [ 0.75966524  0.74529472  0.74101448  0.74061626  0.74528167  0.75279529
  0.76329328  0.77521852  0.78810707  0.80215976]
Iteration 8 [78.6 s]: rank_loss = 0.613733 [29.13 s],
NDCG: [ 0.76342927  0.74836771  0.74286178  0.74326848  0.74719298  0.75506367
  0.76536331  0.77713375  0.78970138  0.80371293]
Iteration 8 [92.7 s]: rank_loss = 0.641887 [29.13 s],
NDCG: [ 0.76145987  0.74563448  0.7410118   0.74110732  0.74567404  0.75348121
  0.76343926  0.77572157  0.78816107  0.80250308]
Iteration 9 [78.7 s]: rank_loss = 0.613389 [29.02 s],
NDCG: [ 0.76327897  0.74686606  0.74244382  0.74296814  0.74736757  0.75485105
  0.76457676  0.77633848  0.78919739  0.80368769]
Iteration 9 [92.6 s]: rank_loss = 0.641850 [29.01 s],
NDCG: [ 0.76365189  0.7462197   0.7417629   0.7418346   0.74683729  0.75434678
  0.76429701  0.7760501   0.78881074  0.80308001]
Iteration 10 [79.2 s]: rank_loss = 0.613868 [29.03 s],
NDCG: [ 0.76156942  0.74626041  0.74270395  0.74227473  0.74701603  0.75489621
  0.76474413  0.77642816  0.7894491   0.80355799]
Iteration 10 [92.6 s]: rank_loss = 0.641604 [28.79 s],
NDCG: [ 0.76220803  0.74637928  0.74088034  0.74077681  0.74577032  0.75362142
  0.76342512  0.7752231   0.78835055  0.80262327]
Iteration 11 [78.4 s]: rank_loss = 0.613651 [28.77 s],
NDCG: [ 0.76156942  0.74621377  0.74135059  0.74185219  0.7466408   0.75430587
  0.76444955  0.77632555  0.78937099  0.80334626]
Iteration 11 [92.9 s]: rank_loss = 0.641562 [29.21 s],
NDCG: [ 0.75938729  0.74501865  0.74060123  0.74085633  0.74622317  0.75354163
  0.76378584  0.77543546  0.78850817  0.80265632]
Iteration 12 [79.0 s]: rank_loss = 0.613094 [29.19 s],
NDCG: [ 0.76238379  0.74765663  0.74231488  0.74254474  0.74673316  0.7544547
  0.76454728  0.77610998  0.78956625  0.80381681]
Iteration 12 [93.3 s]: rank_loss = 0.641098 [29.31 s],
NDCG: [ 0.7603056   0.74484985  0.74047916  0.74091182  0.74530012  0.75268768
  0.76282346  0.77508226  0.78805574  0.8024766 ]
Iteration 13 [79.5 s]: rank_loss = 0.613232 [29.17 s],
NDCG: [ 0.76185555  0.74735222  0.742633    0.74232365  0.74664542  0.75446133
  0.76473152  0.7764269   0.78933047  0.80353532]
Iteration 13 [92.0 s]: rank_loss = 0.641832 [28.19 s],
NDCG: [ 0.7609783   0.74616436  0.7415597   0.74141825  0.74604712  0.753618
  0.76382945  0.77553502  0.78869278  0.80274896]
Iteration 14 [76.9 s]: rank_loss = 0.613451 [28.05 s],
NDCG: [ 0.76110802  0.74638039  0.74160565  0.74194818  0.7464297   0.75418157
  0.76383427  0.77591488  0.78915591  0.80340308]
Iteration 14 [90.8 s]: rank_loss = 0.641560 [28.07 s],
NDCG: [ 0.76154225  0.74596419  0.74108521  0.74089511  0.74563479  0.75340873
  0.76329926  0.77502515  0.78846367  0.80292687]
Iteration 15 [77.1 s]: rank_loss = 0.613247 [28.50 s],
NDCG: [ 0.76017273  0.74622975  0.74201458  0.74175685  0.74620974  0.75411577
  0.76434619  0.77587498  0.78918938  0.80337485]
Iteration 15 [91.3 s]: rank_loss = 0.642019 [27.33 s],
NDCG: [ 0.76004934  0.74598729  0.74066597  0.74105072  0.74561871  0.75364614
  0.76373566  0.77555782  0.7885799   0.80280235]
Iteration 16 [77.0 s]: rank_loss = 0.612934 [27.95 s],
NDCG: [ 0.76083617  0.74703222  0.74297749  0.74274412  0.74678065  0.7544507
  0.76471393  0.77649376  0.7896656   0.80364028]
Iteration 16 [90.3 s]: rank_loss = 0.641264 [28.04 s],
NDCG: [ 0.76195334  0.74639145  0.74259302  0.74287854  0.7466205   0.75386101
  0.76404962  0.77607591  0.7893026   0.80322508]
Iteration 17 [77.0 s]: rank_loss = 0.612704 [27.28 s],
NDCG: [ 0.76182914  0.74702778  0.74242632  0.74265103  0.74732919  0.75513415
  0.7652144   0.77685576  0.78977175  0.80362814]
Iteration 17 [90.7 s]: rank_loss = 0.641153 [28.10 s],
NDCG: [ 0.76079624  0.74682827  0.7416642   0.74152468  0.74660408  0.75430579
  0.7645033   0.77576919  0.78882577  0.80277662]
Iteration 18 [76.9 s]: rank_loss = 0.613481 [27.88 s],
NDCG: [ 0.76105313  0.74723893  0.74295866  0.74244733  0.74730526  0.75474049
  0.76524802  0.77655921  0.78938195  0.80368024]
Iteration 18 [90.4 s]: rank_loss = 0.641012 [28.07 s],
NDCG: [ 0.76277494  0.74714241  0.74234497  0.74280127  0.74680236  0.75489769
  0.76513348  0.77652503  0.78939418  0.80351987]
Iteration 19 [77.1 s]: rank_loss = 0.613189 [28.00 s],
NDCG: [ 0.76066984  0.74649983  0.74242457  0.74225938  0.74679583  0.75469402
  0.76463635  0.77625985  0.78898133  0.80344532]
Iteration 19 [90.4 s]: rank_loss = 0.640552 [28.14 s],
NDCG: [ 0.75899582  0.74510797  0.74131876  0.74098932  0.7456866   0.75358551
  0.76342836  0.77504987  0.78800323  0.80248067]
End. Best Iteration 12.



3. Update for rank_u with rating initialization
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [351.2 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [33.3], Init: 
Init_NDCG: [ 0.56138905  0.56660478  0.57314163  0.58355276  0.59590144  0.61033113
  0.62721119  0.64590306  0.66583025  0.68759003]
RatingInit_NDCG: [ 0.55067452  0.55950643  0.56926048  0.57937974  0.5925191   0.60757687
  0.6247652   0.64356505  0.66365497  0.68604586]
Iteration 0 [81.9 s]: rank_loss = 0.632317 [32.38 s],
NDCG: [ 0.73609815  0.7263067   0.7255052   0.72794024  0.73424191  0.74334088
  0.75424781  0.76679503  0.78045468  0.79496166]
Iteration 1 [79.2 s]: rank_loss = 0.616398 [32.91 s],
NDCG: [ 0.74032188  0.7310089   0.72912054  0.73191847  0.73754825  0.74557225
  0.75591005  0.76833077  0.78211952  0.79663494]
Iteration 2 [79.9 s]: rank_loss = 0.615341 [30.92 s],
NDCG: [ 0.74174642  0.73116884  0.72911214  0.73182073  0.73832092  0.74668895
  0.7567254   0.76863387  0.78231081  0.79664626]
Iteration 3 [78.7 s]: rank_loss = 0.614782 [30.40 s],
NDCG: [ 0.7421316   0.732379    0.73097139  0.73311344  0.73867149  0.74761595
  0.757723    0.76986446  0.78314335  0.79778997]
Iteration 4 [77.8 s]: rank_loss = 0.614118 [29.67 s],
NDCG: [ 0.74255181  0.73068054  0.72858264  0.73212937  0.73786462  0.74645223
  0.75716119  0.76911415  0.78252729  0.79692436]
Iteration 5 [80.2 s]: rank_loss = 0.613934 [26.61 s],
NDCG: [ 0.74069214  0.73070532  0.72841181  0.73090736  0.73664004  0.74564665
  0.75671254  0.76895283  0.78252058  0.79676074]
Iteration 6 [109.5 s]: rank_loss = 0.613895 [27.15 s],
NDCG: [ 0.73910365  0.73004003  0.72678656  0.72968451  0.7365458   0.74528945
  0.75558716  0.76807069  0.78188768  0.796635  ]
Iteration 7 [93.6 s]: rank_loss = 0.613719 [28.59 s],
NDCG: [ 0.74047249  0.73033756  0.72724932  0.73015672  0.73605334  0.7452576
  0.7559172   0.76785549  0.78146269  0.79641538]
Iteration 8 [118.4 s]: rank_loss = 0.613670 [28.20 s],
NDCG: [ 0.73857855  0.72970318  0.72695181  0.72877619  0.73550216  0.74427393
  0.75504765  0.76754573  0.78147031  0.79602756]
Iteration 9 [95.1 s]: rank_loss = 0.613431 [29.06 s],
NDCG: [ 0.73802704  0.72988224  0.72691315  0.72980104  0.73605882  0.74493447
  0.75545256  0.76804123  0.7820996   0.79643014]
Iteration 10 [103.8 s]: rank_loss = 0.613543 [29.95 s],
NDCG: [ 0.73615933  0.72672303  0.72496081  0.72750438  0.73424779  0.7430865
  0.75444267  0.7668699   0.78086899  0.79533406]
Iteration 11 [125.9 s]: rank_loss = 0.613247 [28.71 s],
NDCG: [ 0.73612079  0.72622862  0.72341772  0.72597033  0.73322471  0.74175467
  0.75345726  0.76615228  0.77991003  0.79452323]
Iteration 12 [144.9 s]: rank_loss = 0.613334 [28.63 s],
NDCG: [ 0.73089058  0.72443433  0.72176729  0.72458678  0.73096895  0.74039354
  0.75156743  0.76464174  0.77845738  0.79340152]
Iteration 13 [143.1 s]: rank_loss = 0.612944 [28.44 s],
NDCG: [ 0.72999666  0.72180572  0.72127283  0.72433554  0.73074238  0.74022967
  0.75145615  0.76407358  0.77821703  0.79294773]
Iteration 14 [140.1 s]: rank_loss = 0.612763 [26.78 s],
NDCG: [ 0.72459917  0.71999451  0.71941448  0.72198827  0.72898195  0.73805254
  0.74961902  0.76279994  0.77669066  0.79165278]
Iteration 15 [137.1 s]: rank_loss = 0.612986 [25.65 s],
NDCG: [ 0.72462136  0.71766846  0.71651231  0.72005603  0.72754194  0.73706643
  0.74784177  0.7611171   0.77553077  0.7905588 ]
Iteration 16 [109.6 s]: rank_loss = 0.612640 [25.35 s],
NDCG: [ 0.72196663  0.71560842  0.7151169   0.71863883  0.7261549   0.73576669
  0.74693491  0.75982517  0.77425393  0.78947327]
Iteration 17 [78.7 s]: rank_loss = 0.612725 [27.42 s],
NDCG: [ 0.72304463  0.71315388  0.71326611  0.71749803  0.72474146  0.73460242
  0.74600459  0.75921918  0.77355443  0.78896821]
Iteration 18 [79.3 s]: rank_loss = 0.612647 [26.17 s],
NDCG: [ 0.71806282  0.71027415  0.70966246  0.7140949   0.72216497  0.73194182
  0.74352785  0.75713045  0.7714595   0.78692889]
Iteration 19 [83.6 s]: rank_loss = 0.612559 [27.22 s],
NDCG: [ 0.71514038  0.70693277  0.7078819   0.71137411  0.71975788  0.73005012
  0.74199569  0.75579458  0.77040798  0.78584912]
End. Best Iteration 3.

4. Alternate update for rank_u and rank_i with rating initialization, Delete labels equaling to 0.5
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
v10_2Embed_2MLPshare/MLP.py:170: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer
  np.delete(train_user, train_user[:, 3] == 0.5, axis = 0)
v10_2Embed_2MLPshare/MLP.py:171: FutureWarning: in the future insert will treat boolean arrays and array-likes as boolean index instead of casting it to integer
  np.delete(train_item, train_item[:, 3] == 0.5, axis = 0)
Load data done [369.9 s]. #user=13679, #item=12922, #train_user=15651858, #train_item=20462698, #test=316795
Time: [32.9], Init: 
Init_NDCG: [ 0.55382645  0.56047564  0.56854947  0.57909706  0.59176499  0.60684071
  0.62359544  0.64267233  0.66336415  0.68555833]
RatingInit_NDCG: [ 0.56395771  0.56609623  0.57388792  0.58397524  0.59686008  0.61140106
  0.62782714  0.64606973  0.66641648  0.68830806]
Iteration 0 [80.2 s]: rank_loss = 0.630014 [32.09 s],
NDCG: [ 0.76025071  0.74544271  0.74119516  0.74081192  0.74553572  0.75318314
  0.76318106  0.77448654  0.78765282  0.80193515]
Iteration 0 [84.9 s]: rank_loss = 0.654503 [30.20 s],
NDCG: [ 0.45374543  0.46919141  0.48419009  0.5001065   0.51770405  0.53652774
  0.55629581  0.57878142  0.60279708  0.62903695]
Iteration 1 [78.6 s]: rank_loss = 0.617947 [27.58 s],
NDCG: [ 0.75761359  0.74331107  0.73904753  0.73977389  0.74407395  0.75163446
  0.76151185  0.77325228  0.78617778  0.80023692]
Iteration 1 [87.0 s]: rank_loss = 0.644385 [27.77 s],
NDCG: [ 0.73377515  0.72340984  0.71937282  0.72071829  0.72677624  0.73542866
  0.74625615  0.7591236   0.77317366  0.78825551]
Iteration 2 [77.5 s]: rank_loss = 0.615495 [30.16 s],
NDCG: [ 0.75444226  0.74027384  0.73497087  0.73549789  0.74003186  0.74797716
  0.75793092  0.77007208  0.78356253  0.79792951]
Iteration 2 [91.1 s]: rank_loss = 0.642913 [28.15 s],
NDCG: [ 0.74480438  0.73087233  0.72665609  0.72717976  0.73182689  0.73966641
  0.74986161  0.76227149  0.77583102  0.79085779]
Iteration 3 [75.8 s]: rank_loss = 0.615386 [29.15 s],
NDCG: [ 0.75259813  0.73945637  0.73448352  0.73497977  0.73890256  0.7468877
  0.7570962   0.76907047  0.78258957  0.79734438]
Iteration 3 [89.3 s]: rank_loss = 0.642392 [30.17 s],
NDCG: [ 0.74260463  0.72955822  0.72460598  0.72539062  0.72916304  0.73703156
  0.74726484  0.75978167  0.77406239  0.78939531]
Iteration 4 [79.7 s]: rank_loss = 0.615016 [30.29 s],
NDCG: [ 0.74005178  0.72699499  0.72113249  0.72049687  0.72467739  0.73182014
  0.74170618  0.75435068  0.76921352  0.78474581]
Iteration 4 [92.3 s]: rank_loss = 0.642338 [29.36 s],
NDCG: [ 0.74748677  0.73375103  0.7286468   0.72917634  0.73352559  0.74165078
  0.75182639  0.76407359  0.77813596  0.79322361]
Iteration 5 [78.7 s]: rank_loss = 0.614267 [29.27 s],
NDCG: [ 0.75177653  0.73757432  0.73303507  0.73294495  0.73784812  0.74517358
  0.75518387  0.76715926  0.780717    0.7954888 ]
Iteration 5 [91.4 s]: rank_loss = 0.641799 [29.23 s],
NDCG: [ 0.75009213  0.73690601  0.73249533  0.73243172  0.73617918  0.7442331
  0.75396884  0.76624137  0.77998445  0.79495332]
Iteration 6 [78.0 s]: rank_loss = 0.613901 [28.96 s],
NDCG: [ 0.75028425  0.73791165  0.73247472  0.73246518  0.73688655  0.74466793
  0.75500478  0.76715635  0.78094548  0.79584677]
Iteration 6 [90.8 s]: rank_loss = 0.641887 [29.03 s],
NDCG: [ 0.7278293   0.71593933  0.71147578  0.71335625  0.71873856  0.72756923
  0.73809422  0.75154177  0.76657279  0.78202924]
Iteration 7 [78.2 s]: rank_loss = 0.614306 [29.80 s],
NDCG: [ 0.7247721   0.71388305  0.70912525  0.70979394  0.71457827  0.72229537
  0.73263317  0.74572975  0.76040445  0.77621296]
Iteration 7 [91.8 s]: rank_loss = 0.641552 [29.37 s],
NDCG: [ 0.70289934  0.69468053  0.69099606  0.69361102  0.69876758  0.7074727
  0.71847995  0.73262597  0.74843082  0.76517828]
Iteration 8 [79.0 s]: rank_loss = 0.613941 [28.93 s],
NDCG: [ 0.70230853  0.69302772  0.6897547   0.69108449  0.69629407  0.70470283
  0.71601742  0.7299492   0.74562456  0.76263422]
Iteration 8 [92.0 s]: rank_loss = 0.641848 [29.78 s],
NDCG: [ 0.65411818  0.64960984  0.64977608  0.65371926  0.66171025  0.67263546
  0.68563744  0.70125534  0.71870068  0.73735477]
Iteration 9 [79.0 s]: rank_loss = 0.613922 [29.14 s],
NDCG: [ 0.63822631  0.63492027  0.63822653  0.64462112  0.65418552  0.66610554
  0.68003868  0.69653074  0.7143375   0.73329499]

5. Update for rank_u with rating initialization, using nonall dataset
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Time: [31.4], Init: 
Init_NDCG: [ 0.56719521  0.57194209  0.57827502  0.58782244  0.59999062  0.61414007
  0.63071532  0.64874928  0.66905192  0.69090218]
RatingInit_NDCG: [ 0.564155    0.5685003   0.57522368  0.58530107  0.59727637  0.61176048
  0.62827876  0.64646366  0.66639928  0.68846225]
Iteration 0 [81.1 s]: rank_loss = 0.347365 [30.98 s],
NDCG: [ 0.75117521  0.73900762  0.73313761  0.73377461  0.73848096  0.74625606
  0.75600076  0.76771147  0.78093442  0.79522508]
Iteration 1 [81.9 s]: rank_loss = 0.308831 [30.43 s],
NDCG: [ 0.75448866  0.73997792  0.735314    0.73500505  0.73941311  0.74717964
  0.75711334  0.76858667  0.78173247  0.79628181]
Iteration 2 [80.6 s]: rank_loss = 0.307217 [30.06 s],
NDCG: [ 0.75238419  0.7402861   0.73465347  0.73568882  0.73964041  0.74659892
  0.75659046  0.76846841  0.78199161  0.79663405]
Iteration 3 [81.1 s]: rank_loss = 0.307335 [30.40 s],
NDCG: [ 0.75266407  0.73979167  0.73482435  0.73532247  0.7394592   0.74717936
  0.75695057  0.76889543  0.78205684  0.79673419]
Iteration 4 [80.6 s]: rank_loss = 0.306517 [30.10 s],
NDCG: [ 0.75277224  0.73969416  0.73507568  0.73558519  0.73976821  0.74685254
  0.75714447  0.76905414  0.78203422  0.7967305 ]
Iteration 5 [79.6 s]: rank_loss = 0.305289 [30.36 s],
NDCG: [ 0.7541082   0.73971955  0.73569412  0.73615159  0.74041014  0.74780181
  0.75801961  0.76951963  0.78243222  0.79720221]
Iteration 6 [79.4 s]: rank_loss = 0.305826 [30.16 s],
NDCG: [ 0.75272314  0.73961752  0.73496453  0.73585368  0.73974459  0.74753886
  0.75754494  0.76912756  0.78222934  0.79681218]
Iteration 7 [79.0 s]: rank_loss = 0.305842 [30.65 s],
NDCG: [ 0.75242291  0.73830025  0.73382441  0.73576199  0.73993325  0.74750427
  0.75715573  0.76868596  0.78183258  0.79652812]
Iteration 8 [80.9 s]: rank_loss = 0.305289 [31.87 s],
NDCG: [ 0.75063097  0.73822882  0.73380551  0.73507193  0.73940253  0.74712423
  0.75705682  0.76890812  0.78162507  0.79623542]
Iteration 9 [81.0 s]: rank_loss = 0.305552 [30.45 s],
NDCG: [ 0.7525427   0.7386709   0.73496905  0.73574871  0.73987479  0.74742502
  0.75744727  0.76875003  0.78195259  0.79664187]
Iteration 10 [79.7 s]: rank_loss = 0.305658 [31.76 s],
NDCG: [ 0.75122363  0.73827512  0.73450213  0.73521417  0.739297    0.74716503
  0.75733652  0.7688632   0.7815293   0.79628152]
Iteration 11 [80.7 s]: rank_loss = 0.305742 [31.12 s],
NDCG: [ 0.75206881  0.7392382   0.73500518  0.7346787   0.73938726  0.74732427
  0.7572513   0.76876183  0.78167438  0.79641282]
Iteration 12 [79.3 s]: rank_loss = 0.305169 [29.19 s],
NDCG: [ 0.75124564  0.74005934  0.73469559  0.735167    0.73959985  0.74765736
  0.7571586   0.76897559  0.78219393  0.79675572]
Iteration 13 [79.9 s]: rank_loss = 0.305367 [30.21 s],
NDCG: [ 0.75239613  0.73942757  0.73452074  0.73525346  0.73934947  0.74719873
  0.75722656  0.76883189  0.78213203  0.79665058]
Iteration 14 [79.5 s]: rank_loss = 0.304703 [29.06 s],
NDCG: [ 0.75218955  0.74004866  0.73497673  0.73532013  0.73948373  0.74756116
  0.75765309  0.76924654  0.78203418  0.79672896]
Iteration 15 [79.3 s]: rank_loss = 0.304900 [29.13 s],
NDCG: [ 0.75232696  0.73878837  0.73533525  0.7355421   0.73969083  0.7474991
  0.7575647   0.76923411  0.78196727  0.79652202]
Iteration 16 [78.8 s]: rank_loss = 0.304708 [29.12 s],
NDCG: [ 0.74947635  0.73809983  0.73442399  0.73509468  0.73956871  0.74747769
  0.7572916   0.7690122   0.78190534  0.79654756]
Iteration 17 [79.6 s]: rank_loss = 0.305231 [29.16 s],
NDCG: [ 0.75231784  0.73875545  0.73514949  0.73532777  0.73994569  0.74771566
  0.75779073  0.76934398  0.78228894  0.79697147]
Iteration 18 [79.2 s]: rank_loss = 0.305131 [29.22 s],
NDCG: [ 0.75182765  0.73944285  0.73532046  0.73531188  0.73999676  0.7475403
  0.75770345  0.76938111  0.78238135  0.7968505 ]
Iteration 19 [79.3 s]: rank_loss = 0.304861 [29.19 s],
NDCG: [ 0.75289513  0.739664    0.73564362  0.73629481  0.74029867  0.7480472
  0.7580149   0.76944645  0.78239516  0.79708117]
End. Best Iteration 5.

6. Alternate update for rank_u and rank_i with rating initialization, using nonall dataset
liurui@ubuntu:~/DeepRec$ KERAS_BACKEND=theano python v10_2Embed_2MLPshare/MLP.py --learner adam --lr 0.0001 --batch_size_random 1280000
Using Theano backend.
MLP arguments: Namespace(batch_size=256, batch_size_random=1280000, epochs=20, layers='[64,32,16,8]', learner='adam', lr=0.0001, path='Data/yelp/', reg_layers='[0,0,0,0]', verbose=1) 
Load data done [80.4 s]. #user=13679, #item=12922, #train_user=3914489, #train_item=5115233, #test=316795
Time: [32.0], Init: 
Init_NDCG: [ 0.5640135   0.56859154  0.57522265  0.58603656  0.59866405  0.61304983
  0.62938485  0.64802694  0.66818047  0.68983203]
RatingInit_NDCG: [ 0.56135662  0.56661187  0.57511515  0.58531798  0.59749748  0.61171781
  0.62828247  0.64698085  0.66730054  0.689694  ]
Iteration 0 [83.2 s]: rank_loss = 0.342916 [31.63 s],
NDCG: [ 0.75256611  0.73917248  0.73560163  0.73563532  0.73965533  0.74756776
  0.75754477  0.76895992  0.78241956  0.7968704 ]
Iteration 0 [86.7 s]: rank_loss = 0.398896 [30.64 s],
NDCG: [ 0.7626215   0.74804415  0.74280365  0.74280325  0.74732544  0.75427909
  0.76395919  0.77576118  0.788513    0.80272023]
Iteration 1 [82.4 s]: rank_loss = 0.311908 [30.79 s],
NDCG: [ 0.75925199  0.74546127  0.73974226  0.74042428  0.74379983  0.751979
  0.76229083  0.7734787   0.78607975  0.80040608]
Iteration 1 [93.4 s]: rank_loss = 0.387207 [31.03 s],
NDCG: [ 0.76658663  0.75101003  0.74556117  0.74574872  0.74967707  0.75675209
  0.76685971  0.77829766  0.79080228  0.80483855]
Iteration 2 [82.9 s]: rank_loss = 0.310026 [32.39 s],
NDCG: [ 0.75817754  0.74540841  0.74014597  0.74102656  0.74483565  0.75292472
  0.76288947  0.77439511  0.78738468  0.80165357]
Iteration 2 [95.9 s]: rank_loss = 0.385327 [29.86 s],
NDCG: [ 0.76428092  0.75032159  0.74601301  0.74582751  0.74938445  0.75648467
  0.76663699  0.77822756  0.79105585  0.80508585]
Iteration 3 [106.9 s]: rank_loss = 0.308209 [38.54 s],
NDCG: [ 0.76007045  0.74829072  0.74257608  0.74273227  0.74656124  0.75449281
  0.76461821  0.77631914  0.78911831  0.80326414]
Iteration 3 [134.6 s]: rank_loss = 0.383802 [22.02 s],
NDCG: [ 0.76224342  0.75016616  0.74476405  0.74504831  0.74833534  0.75590898
  0.76554768  0.77679911  0.79001079  0.80418431]
Iteration 4 [75.4 s]: rank_loss = 0.307474 [21.62 s],
NDCG: [ 0.75989163  0.74578975  0.74201019  0.74213984  0.74605342  0.75370562
  0.76400545  0.77592371  0.78874457  0.8028503 ]
Iteration 4 [83.0 s]: rank_loss = 0.382785 [21.03 s],
NDCG: [ 0.76043591  0.74854935  0.7432107   0.74301802  0.74699837  0.75459339
  0.76510646  0.7768695   0.78953047  0.8036499 ]
Iteration 5 [69.2 s]: rank_loss = 0.307096 [20.67 s],
NDCG: [ 0.75730828  0.74612655  0.74074742  0.74145396  0.7462695   0.75408059
  0.76359919  0.77531032  0.78819095  0.80266707]
Iteration 5 [82.2 s]: rank_loss = 0.382708 [22.32 s],
NDCG: [ 0.7590004   0.74690946  0.74281296  0.74291656  0.74729473  0.75506693
  0.76481375  0.77663383  0.78911159  0.80331804]
Iteration 6 [72.5 s]: rank_loss = 0.306491 [20.77 s],
NDCG: [ 0.76080428  0.7471674   0.74315101  0.74311324  0.74737795  0.75502183
  0.7647096   0.77636278  0.78911877  0.80335998]
Iteration 6 [81.3 s]: rank_loss = 0.382073 [20.54 s],
NDCG: [ 0.76202503  0.74860668  0.74449044  0.74463485  0.74844559  0.75604309
  0.76572008  0.7773323   0.78986226  0.80391823]
Iteration 7 [69.4 s]: rank_loss = 0.306124 [20.66 s],
NDCG: [ 0.7588842   0.74658394  0.74220758  0.7432057   0.74694618  0.75455701
  0.76431471  0.77563951  0.78836456  0.80269581]
Iteration 7 [80.5 s]: rank_loss = 0.382083 [20.50 s],
NDCG: [ 0.7618304   0.74761209  0.74353165  0.74397127  0.74833631  0.75553288
  0.76498556  0.77664526  0.78931675  0.80308536]
Iteration 8 [69.5 s]: rank_loss = 0.305343 [20.50 s],
NDCG: [ 0.75725393  0.74629657  0.74242095  0.74211758  0.74617218  0.75384426
  0.76342876  0.77491829  0.78771056  0.8019048 ]
Iteration 8 [81.3 s]: rank_loss = 0.381777 [20.53 s],
NDCG: [ 0.75883173  0.74616437  0.74211643  0.74318909  0.74694815  0.75454282
  0.76412367  0.77527498  0.78827167  0.80251571]
Iteration 9 [70.2 s]: rank_loss = 0.305586 [20.40 s],
NDCG: [ 0.75506204  0.74353296  0.73991407  0.7403573   0.74459029  0.75196829
  0.7615306   0.77310821  0.78588349  0.80029441]
Iteration 9 [80.6 s]: rank_loss = 0.381879 [20.60 s],
NDCG: [ 0.75805855  0.74594946  0.74251608  0.74258557  0.7460369   0.75393153
  0.76377314  0.77526746  0.78767101  0.80196647]
Iteration 10 [69.3 s]: rank_loss = 0.305438 [20.41 s],
NDCG: [ 0.7561638   0.74588176  0.74050421  0.74050359  0.74452112  0.75185042
  0.76146701  0.77284698  0.78574198  0.80029817]
Iteration 10 [82.1 s]: rank_loss = 0.381604 [20.49 s],
NDCG: [ 0.75495797  0.74555655  0.74058505  0.74106209  0.7453789   0.75284336
  0.76266419  0.77401724  0.78664556  0.80102581]
Iteration 11 [70.5 s]: rank_loss = 0.305677 [21.51 s],
NDCG: [ 0.75306385  0.7413961   0.73709486  0.73729625  0.74158416  0.74906297
  0.75917392  0.77054056  0.78331006  0.79817418]
Iteration 11 [80.9 s]: rank_loss = 0.381878 [20.50 s],
NDCG: [ 0.7545033   0.74172535  0.73748897  0.73797291  0.74188136  0.74958873
  0.75949246  0.77127988  0.78395407  0.79875925]
Iteration 12 [69.5 s]: rank_loss = 0.304920 [20.77 s],
NDCG: [ 0.7457147   0.73377678  0.72917229  0.73030934  0.73518456  0.74271284
  0.75315035  0.76490761  0.77850463  0.79372469]
Iteration 12 [83.6 s]: rank_loss = 0.381383 [21.52 s],
NDCG: [ 0.75113231  0.73917216  0.73381702  0.73438542  0.73850365  0.74664707
  0.75681055  0.76845963  0.78169053  0.79663023]
Iteration 13 [74.5 s]: rank_loss = 0.305062 [27.19 s],
NDCG: [ 0.72997186  0.7201063   0.71798492  0.72062531  0.7260422   0.73472343
  0.74589877  0.75815781  0.7721893   0.7876068 ]
Iteration 13 [84.3 s]: rank_loss = 0.381315 [26.82 s],
NDCG: [ 0.73547814  0.72373752  0.72191136  0.7234463   0.7292981   0.73745057
  0.74842321  0.7605698   0.77428747  0.78978265]
Iteration 14 [70.2 s]: rank_loss = 0.305190 [20.59 s],
NDCG: [ 0.7007482   0.69836618  0.70038783  0.7052598   0.71288234  0.72313857
  0.7350679   0.74872682  0.7634247   0.77931207]
Iteration 14 [81.0 s]: rank_loss = 0.382049 [21.92 s],
NDCG: [ 0.70039698  0.69701998  0.69920241  0.70369077  0.71181644  0.72237397
  0.73448344  0.74802484  0.762831    0.77887448]
Iteration 15 [121.7 s]: rank_loss = 0.305306 [25.40 s],
NDCG: [ 0.68084578  0.68349751  0.68897206  0.69583626  0.70453002  0.71591946
  0.72839045  0.74259461  0.75795107  0.77417597]
Iteration 15 [81.4 s]: rank_loss = 0.380919 [20.55 s],
NDCG: [ 0.64991791  0.65922879  0.66749788  0.67766115  0.68894415  0.70197801
  0.71587328  0.73108722  0.74696057  0.76387683]
Iteration 16 [70.5 s]: rank_loss = 0.304914 [20.62 s],
NDCG: [ 0.61867466  0.63972397  0.65401552  0.66724272  0.67973857  0.69412852
  0.7084327   0.72441199  0.74105404  0.75813962]
Iteration 16 [82.8 s]: rank_loss = 0.381363 [21.36 s],
NDCG: [ 0.61733582  0.63637771  0.6493897   0.66235864  0.67532149  0.69001535
  0.70495136  0.72100897  0.7374565   0.75499042]
Iteration 17 [71.7 s]: rank_loss = 0.305091 [21.39 s],
NDCG: [ 0.6025498   0.62626473  0.64323867  0.65748894  0.67175981  0.68604238
  0.70152058  0.71768264  0.73470473  0.75245995]
Iteration 17 [83.4 s]: rank_loss = 0.381117 [21.37 s],
NDCG: [ 0.60714895  0.62729354  0.6409854   0.65470858  0.66919982  0.68374895
  0.69939089  0.71566055  0.7323927   0.75051875]
Iteration 18 [71.9 s]: rank_loss = 0.305153 [21.42 s],
NDCG: [ 0.59386275  0.6209636   0.63792744  0.65343515  0.66784204  0.68251684
  0.69836237  0.71472337  0.73185748  0.74996762]
Iteration 18 [82.9 s]: rank_loss = 0.381064 [21.42 s],
NDCG: [ 0.5872698   0.61082698  0.6272518   0.64254792  0.65701136  0.67289431
  0.68885067  0.7059918   0.72379673  0.74263992]
Iteration 19 [71.8 s]: rank_loss = 0.304922 [21.42 s],
NDCG: [ 0.57394744  0.60160371  0.62089346  0.63782806  0.65428632  0.67042422
  0.68756193  0.70408427  0.72227752  0.74095803]
Iteration 19 [83.1 s]: rank_loss = 0.380776 [21.47 s],
NDCG: [ 0.58488171  0.60838878  0.62575538  0.64179923  0.65669501  0.67244191
  0.68906304  0.70594839  0.72370386  0.74209823]
End. Best Iteration 2.


